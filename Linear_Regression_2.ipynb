{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6c6d2cc",
   "metadata": {},
   "source": [
    "Linear Regression using the loss function: \\begin{equation}|x - x(i)|^{3}\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d92900c",
   "metadata": {},
   "source": [
    "Here we use this loss function to fit the line:\\begin{equation}y = mx + c\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc9ddfa",
   "metadata": {},
   "source": [
    "where we calculate the slope and the intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c58c367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1da4e36b880>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "\n",
    "X = np.linspace(2,98,100)\n",
    "y = np.linspace(2,100,100)\n",
    "X = X/np.max(X) #Normalising the data by dividing the elements with the max value\n",
    "y=y/np.max(y)  #Scaling the data by dividing the elements with the max value\n",
    "plt.scatter(X,y)\n",
    "plt.grid()\n",
    "plt.xlabel(\"input\");\n",
    "plt.ylabel(\"output\");\n",
    "plt.legend(['Actual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ad409d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01795918 0.02666667 0.03537415 0.04408163 0.05278912 0.0614966\n",
      " 0.07020408 0.07891156 0.08761905 0.09632653 0.10503401 0.1137415\n",
      " 0.12244898 0.13115646 0.13986395 0.14857143 0.15727891 0.16598639\n",
      " 0.17469388 0.18340136 0.19210884 0.20081633 0.20952381 0.21823129\n",
      " 0.22693878 0.23564626 0.24435374 0.25306122 0.26176871 0.27047619\n",
      " 0.27918367 0.28789116 0.29659864 0.30530612 0.31401361 0.32272109\n",
      " 0.33142857 0.34013605 0.34884354 0.35755102 0.3662585  0.37496599\n",
      " 0.38367347 0.39238095 0.40108844 0.40979592 0.4185034  0.42721088\n",
      " 0.43591837 0.44462585 0.45333333 0.46204082 0.4707483  0.47945578\n",
      " 0.48816327 0.49687075 0.50557823 0.51428571 0.5229932  0.53170068\n",
      " 0.54040816 0.54911565 0.55782313 0.56653061 0.5752381  0.58394558\n",
      " 0.59265306 0.60136054 0.61006803 0.61877551 0.62748299 0.63619048\n",
      " 0.64489796 0.65360544 0.66231293 0.67102041 0.67972789 0.68843537\n",
      " 0.69714286 0.70585034 0.71455782 0.72326531 0.73197279 0.74068027\n",
      " 0.74938776 0.75809524 0.76680272 0.7755102  0.78421769 0.79292517\n",
      " 0.80163265 0.81034014 0.81904762 0.8277551  0.83646259 0.84517007\n",
      " 0.85387755 0.86258503 0.87129252 0.88      ]\n"
     ]
    }
   ],
   "source": [
    "#calculating the output with randomly initialised weights and biases\n",
    "w= 0.88\n",
    "bias = 0\n",
    "y_pred = X*w +  bias\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85214a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses=[]\n",
    "def calculate_gradient():\n",
    "    lr = 0.0001\n",
    "    iterations = 2000\n",
    "    N = float(len(X))\n",
    "    w= 0.88\n",
    "    bias = 0\n",
    "    weights_and_bias = []\n",
    "    for i in range(iterations):\n",
    "        y_pred = X*w + bias\n",
    "        loss = sum((y_pred-y)**3)/N\n",
    "        der_w = -(3*sum(X*(y_pred - y)**2))/N\n",
    "        der_b = -(3*sum((y_pred-y)**2))/N\n",
    "        w = w - lr*der_w\n",
    "        bias = bias - lr*der_b\n",
    "        losses.append(loss)\n",
    "        print(\"Training loss: {}\".format(loss))\n",
    "        \n",
    "    weights_and_bias.append(w)\n",
    "    weights_and_bias.append(bias)\n",
    "    return weights_and_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07ee0123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: -0.00044376219590356594\n",
      "Training loss: -0.0004437281952722095\n",
      "Training loss: -0.0004436941982912187\n",
      "Training loss: -0.0004436602049600943\n",
      "Training loss: -0.0004436262152783321\n",
      "Training loss: -0.0004435922292454328\n",
      "Training loss: -0.00044355824686089304\n",
      "Training loss: -0.0004435242681242148\n",
      "Training loss: -0.0004434902930348942\n",
      "Training loss: -0.0004434563215924317\n",
      "Training loss: -0.00044342235379632547\n",
      "Training loss: -0.000443388389646076\n",
      "Training loss: -0.00044335442914118306\n",
      "Training loss: -0.00044332047228114456\n",
      "Training loss: -0.0004432865190654598\n",
      "Training loss: -0.00044325256949362814\n",
      "Training loss: -0.00044321862356514987\n",
      "Training loss: -0.0004431846812795263\n",
      "Training loss: -0.00044315074263625486\n",
      "Training loss: -0.00044311680763483625\n",
      "Training loss: -0.00044308287627476995\n",
      "Training loss: -0.0004430489485555574\n",
      "Training loss: -0.00044301502447669644\n",
      "Training loss: -0.00044298110403769074\n",
      "Training loss: -0.00044294718723803623\n",
      "Training loss: -0.0004429132740772368\n",
      "Training loss: -0.000442879364554792\n",
      "Training loss: -0.0004428454586702007\n",
      "Training loss: -0.000442811556422967\n",
      "Training loss: -0.00044277765781258803\n",
      "Training loss: -0.0004427437628385658\n",
      "Training loss: -0.00044270987150040174\n",
      "Training loss: -0.00044267598379759554\n",
      "Training loss: -0.0004426420997296496\n",
      "Training loss: -0.0004426082192960656\n",
      "Training loss: -0.0004425743424963434\n",
      "Training loss: -0.00044254046932998314\n",
      "Training loss: -0.00044250659979648907\n",
      "Training loss: -0.00044247273389536274\n",
      "Training loss: -0.000442438871626102\n",
      "Training loss: -0.00044240501298821184\n",
      "Training loss: -0.0004423711579811939\n",
      "Training loss: -0.00044233730660454796\n",
      "Training loss: -0.000442303458857776\n",
      "Training loss: -0.00044226961474038155\n",
      "Training loss: -0.0004422357742518654\n",
      "Training loss: -0.0004422019373917292\n",
      "Training loss: -0.0004421681041594773\n",
      "Training loss: -0.00044213427455461104\n",
      "Training loss: -0.00044210044857663185\n",
      "Training loss: -0.00044206662622504395\n",
      "Training loss: -0.00044203280749934763\n",
      "Training loss: -0.00044199899239904584\n",
      "Training loss: -0.0004419651809236428\n",
      "Training loss: -0.000441931373072642\n",
      "Training loss: -0.0004418975688455437\n",
      "Training loss: -0.00044186376824185085\n",
      "Training loss: -0.00044182997126106867\n",
      "Training loss: -0.00044179617790269935\n",
      "Training loss: -0.00044176238816624654\n",
      "Training loss: -0.00044172860205121114\n",
      "Training loss: -0.0004416948195571001\n",
      "Training loss: -0.0004416610406834141\n",
      "Training loss: -0.00044162726542965714\n",
      "Training loss: -0.0004415934937953336\n",
      "Training loss: -0.0004415597257799476\n",
      "Training loss: -0.0004415259613830012\n",
      "Training loss: -0.00044149220060399954\n",
      "Training loss: -0.00044145844344244627\n",
      "Training loss: -0.00044142468989784474\n",
      "Training loss: -0.00044139093996970033\n",
      "Training loss: -0.00044135719365751545\n",
      "Training loss: -0.0004413234509607953\n",
      "Training loss: -0.0004412897118790453\n",
      "Training loss: -0.000441255976411769\n",
      "Training loss: -0.00044122224455846973\n",
      "Training loss: -0.00044118851631865403\n",
      "Training loss: -0.0004411547916918259\n",
      "Training loss: -0.0004411210706774888\n",
      "Training loss: -0.0004410873532751482\n",
      "Training loss: -0.00044105363948431203\n",
      "Training loss: -0.0004410199293044804\n",
      "Training loss: -0.0004409862227351622\n",
      "Training loss: -0.0004409525197758601\n",
      "Training loss: -0.0004409188204260811\n",
      "Training loss: -0.0004408851246853288\n",
      "Training loss: -0.0004408514325531092\n",
      "Training loss: -0.0004408177440289286\n",
      "Training loss: -0.0004407840591122935\n",
      "Training loss: -0.00044075037780270677\n",
      "Training loss: -0.0004407167000996757\n",
      "Training loss: -0.0004406830260027065\n",
      "Training loss: -0.00044064935551130306\n",
      "Training loss: -0.0004406156886249747\n",
      "Training loss: -0.000440582025343224\n",
      "Training loss: -0.00044054836566556025\n",
      "Training loss: -0.0004405147095914879\n",
      "Training loss: -0.00044048105712051253\n",
      "Training loss: -0.00044044740825214206\n",
      "Training loss: -0.00044041376298588266\n",
      "Training loss: -0.0004403801213212395\n",
      "Training loss: -0.00044034648325772164\n",
      "Training loss: -0.00044031284879483443\n",
      "Training loss: -0.0004402792179320842\n",
      "Training loss: -0.00044024559066897827\n",
      "Training loss: -0.000440211967005024\n",
      "Training loss: -0.00044017834693972743\n",
      "Training loss: -0.0004401447304725976\n",
      "Training loss: -0.0004401111176031406\n",
      "Training loss: -0.0004400775083308631\n",
      "Training loss: -0.0004400439026552723\n",
      "Training loss: -0.0004400103005758781\n",
      "Training loss: -0.00043997670209218513\n",
      "Training loss: -0.000439943107203702\n",
      "Training loss: -0.00043990951590993586\n",
      "Training loss: -0.0004398759282103965\n",
      "Training loss: -0.0004398423441045894\n",
      "Training loss: -0.00043980876359202433\n",
      "Training loss: -0.0004397751866722079\n",
      "Training loss: -0.00043974161334465014\n",
      "Training loss: -0.00043970804360885657\n",
      "Training loss: -0.0004396744774643369\n",
      "Training loss: -0.0004396409149105999\n",
      "Training loss: -0.00043960735594715403\n",
      "Training loss: -0.0004395738005735081\n",
      "Training loss: -0.000439540248789168\n",
      "Training loss: -0.000439506700593644\n",
      "Training loss: -0.0004394731559864465\n",
      "Training loss: -0.0004394396149670816\n",
      "Training loss: -0.0004394060775350607\n",
      "Training loss: -0.0004393725436898921\n",
      "Training loss: -0.0004393390134310846\n",
      "Training loss: -0.0004393054867581474\n",
      "Training loss: -0.00043927196367058954\n",
      "Training loss: -0.0004392384441679198\n",
      "Training loss: -0.00043920492824964827\n",
      "Training loss: -0.00043917141591528445\n",
      "Training loss: -0.00043913790716433696\n",
      "Training loss: -0.0004391044019963164\n",
      "Training loss: -0.0004390709004107325\n",
      "Training loss: -0.00043903740240709634\n",
      "Training loss: -0.0004390039079849152\n",
      "Training loss: -0.00043897041714370137\n",
      "Training loss: -0.00043893692988296323\n",
      "Training loss: -0.0004389034462022117\n",
      "Training loss: -0.0004388699661009576\n",
      "Training loss: -0.0004388364895787079\n",
      "Training loss: -0.0004388030166349776\n",
      "Training loss: -0.0004387695472692741\n",
      "Training loss: -0.0004387360814811089\n",
      "Training loss: -0.0004387026192699924\n",
      "Training loss: -0.0004386691606354367\n",
      "Training loss: -0.0004386357055769505\n",
      "Training loss: -0.00043860225409404616\n",
      "Training loss: -0.00043856880618623406\n",
      "Training loss: -0.000438535361853025\n",
      "Training loss: -0.0004385019210939301\n",
      "Training loss: -0.0004384684839084609\n",
      "Training loss: -0.00043843505029612906\n",
      "Training loss: -0.00043840162025644494\n",
      "Training loss: -0.0004383681937889212\n",
      "Training loss: -0.00043833477089306777\n",
      "Training loss: -0.00043830135156839824\n",
      "Training loss: -0.0004382679358144226\n",
      "Training loss: -0.0004382345236306522\n",
      "Training loss: -0.0004382011150165999\n",
      "Training loss: -0.00043816770997177846\n",
      "Training loss: -0.000438134308495699\n",
      "Training loss: -0.0004381009105878735\n",
      "Training loss: -0.0004380675162478137\n",
      "Training loss: -0.00043803412547503354\n",
      "Training loss: -0.00043800073826904276\n",
      "Training loss: -0.0004379673546293553\n",
      "Training loss: -0.00043793397455548297\n",
      "Training loss: -0.0004379005980469397\n",
      "Training loss: -0.0004378672251032369\n",
      "Training loss: -0.0004378338557238874\n",
      "Training loss: -0.00043780048990840536\n",
      "Training loss: -0.00043776712765630207\n",
      "Training loss: -0.00043773376896709106\n",
      "Training loss: -0.0004377004138402832\n",
      "Training loss: -0.0004376670622753952\n",
      "Training loss: -0.00043763371427193954\n",
      "Training loss: -0.0004376003698294284\n",
      "Training loss: -0.00043756702894737486\n",
      "Training loss: -0.0004375336916252928\n",
      "Training loss: -0.0004375003578626964\n",
      "Training loss: -0.00043746702765909694\n",
      "Training loss: -0.0004374337010140115\n",
      "Training loss: -0.00043740037792695303\n",
      "Training loss: -0.00043736705839743324\n",
      "Training loss: -0.00043733374242496887\n",
      "Training loss: -0.00043730043000907084\n",
      "Training loss: -0.0004372671211492551\n",
      "Training loss: -0.0004372338158450358\n",
      "Training loss: -0.0004372005140959278\n",
      "Training loss: -0.0004371672159014446\n",
      "Training loss: -0.0004371339212611014\n",
      "Training loss: -0.0004371006301744107\n",
      "Training loss: -0.00043706734264088975\n",
      "Training loss: -0.0004370340586600506\n",
      "Training loss: -0.0004370007782314097\n",
      "Training loss: -0.000436967501354482\n",
      "Training loss: -0.0004369342280287801\n",
      "Training loss: -0.00043690095825382074\n",
      "Training loss: -0.00043686769202911946\n",
      "Training loss: -0.00043683442935419113\n",
      "Training loss: -0.00043680117022855007\n",
      "Training loss: -0.00043676791465171327\n",
      "Training loss: -0.00043673466262319376\n",
      "Training loss: -0.0004367014141425071\n",
      "Training loss: -0.0004366681692091714\n",
      "Training loss: -0.0004366349278227001\n",
      "Training loss: -0.00043660168998261033\n",
      "Training loss: -0.00043656845568841677\n",
      "Training loss: -0.0004365352249396351\n",
      "Training loss: -0.000436501997735783\n",
      "Training loss: -0.00043646877407637377\n",
      "Training loss: -0.0004364355539609252\n",
      "Training loss: -0.0004364023373889544\n",
      "Training loss: -0.0004363691243599754\n",
      "Training loss: -0.00043633591487350577\n",
      "Training loss: -0.0004363027089290619\n",
      "Training loss: -0.0004362695065261594\n",
      "Training loss: -0.0004362363076643165\n",
      "Training loss: -0.00043620311234304955\n",
      "Training loss: -0.00043616992056187215\n",
      "Training loss: -0.00043613673232030504\n",
      "Training loss: -0.00043610354761786373\n",
      "Training loss: -0.0004360703664540655\n",
      "Training loss: -0.0004360371888284264\n",
      "Training loss: -0.00043600401474046447\n",
      "Training loss: -0.0004359708441896964\n",
      "Training loss: -0.0004359376771756393\n",
      "Training loss: -0.00043590451369781284\n",
      "Training loss: -0.0004358713537557307\n",
      "Training loss: -0.00043583819734891257\n",
      "Training loss: -0.00043580504447687617\n",
      "Training loss: -0.0004357718951391388\n",
      "Training loss: -0.0004357387493352184\n",
      "Training loss: -0.0004357056070646318\n",
      "Training loss: -0.0004356724683268984\n",
      "Training loss: -0.0004356393331215349\n",
      "Training loss: -0.00043560620144806147\n",
      "Training loss: -0.0004355730733059944\n",
      "Training loss: -0.0004355399486948521\n",
      "Training loss: -0.00043550682761415267\n",
      "Training loss: -0.0004354737100634161\n",
      "Training loss: -0.00043544059604215855\n",
      "Training loss: -0.0004354074855499018\n",
      "Training loss: -0.0004353743785861603\n",
      "Training loss: -0.00043534127515045635\n",
      "Training loss: -0.00043530817524230827\n",
      "Training loss: -0.00043527507886123205\n",
      "Training loss: -0.0004352419860067499\n",
      "Training loss: -0.0004352088966783795\n",
      "Training loss: -0.0004351758108756402\n",
      "Training loss: -0.0004351427285980513\n",
      "Training loss: -0.000435109649845131\n",
      "Training loss: -0.00043507657461640156\n",
      "Training loss: -0.0004350435029113785\n",
      "Training loss: -0.0004350104347295846\n",
      "Training loss: -0.00043497737007053755\n",
      "Training loss: -0.0004349443089337569\n",
      "Training loss: -0.0004349112513187639\n",
      "Training loss: -0.00043487819722507604\n",
      "Training loss: -0.00043484514665221614\n",
      "Training loss: -0.0004348120995997027\n",
      "Training loss: -0.00043477905606705567\n",
      "Training loss: -0.00043474601605379535\n",
      "Training loss: -0.0004347129795594419\n",
      "Training loss: -0.00043467994658351534\n",
      "Training loss: -0.000434646917125537\n",
      "Training loss: -0.000434613891185027\n",
      "Training loss: -0.0004345808687615048\n",
      "Training loss: -0.00043454784985449377\n",
      "Training loss: -0.0004345148344635121\n",
      "Training loss: -0.00043448182258808214\n",
      "Training loss: -0.0004344488142277219\n",
      "Training loss: -0.0004344158093819546\n",
      "Training loss: -0.00043438280805030254\n",
      "Training loss: -0.00043434981023228377\n",
      "Training loss: -0.0004343168159274222\n",
      "Training loss: -0.00043428382513523595\n",
      "Training loss: -0.0004342508378552504\n",
      "Training loss: -0.00043421785408698254\n",
      "Training loss: -0.000434184873829958\n",
      "Training loss: -0.00043415189708369473\n",
      "Training loss: -0.00043411892384771745\n",
      "Training loss: -0.0004340859541215469\n",
      "Training loss: -0.0004340529879047029\n",
      "Training loss: -0.0004340200251967098\n",
      "Training loss: -0.0004339870659970876\n",
      "Training loss: -0.00043395411030536127\n",
      "Training loss: -0.0004339211581210505\n",
      "Training loss: -0.00043388820944367747\n",
      "Training loss: -0.0004338552642727667\n",
      "Training loss: -0.00043382232260783747\n",
      "Training loss: -0.00043378938444841447\n",
      "Training loss: -0.0004337564497940199\n",
      "Training loss: -0.0004337235186441754\n",
      "Training loss: -0.0004336905909984028\n",
      "Training loss: -0.00043365766685622714\n",
      "Training loss: -0.0004336247462171717\n",
      "Training loss: -0.0004335918290807557\n",
      "Training loss: -0.00043355891544650583\n",
      "Training loss: -0.00043352600531394313\n",
      "Training loss: -0.00043349309868259163\n",
      "Training loss: -0.0004334601955519751\n",
      "Training loss: -0.0004334272959216142\n",
      "Training loss: -0.0004333943997910347\n",
      "Training loss: -0.0004333615071597591\n",
      "Training loss: -0.0004333286180273136\n",
      "Training loss: -0.00043329573239321746\n",
      "Training loss: -0.00043326285025699763\n",
      "Training loss: -0.00043322997161817614\n",
      "Training loss: -0.0004331970964762781\n",
      "Training loss: -0.0004331642248308263\n",
      "Training loss: -0.00043313135668134474\n",
      "Training loss: -0.00043309849202735726\n",
      "Training loss: -0.0004330656308683905\n",
      "Training loss: -0.00043303277320396496\n",
      "Training loss: -0.00043299991903360854\n",
      "Training loss: -0.0004329670683568443\n",
      "Training loss: -0.0004329342211731952\n",
      "Training loss: -0.00043290137748218697\n",
      "Training loss: -0.00043286853728334525\n",
      "Training loss: -0.00043283570057619353\n",
      "Training loss: -0.00043280286736025755\n",
      "Training loss: -0.00043277003763505953\n",
      "Training loss: -0.0004327372114001288\n",
      "Training loss: -0.0004327043886549871\n",
      "Training loss: -0.0004326715693991613\n",
      "Training loss: -0.000432638753632175\n",
      "Training loss: -0.00043260594135355394\n",
      "Training loss: -0.0004325731325628244\n",
      "Training loss: -0.0004325403272595102\n",
      "Training loss: -0.00043250752544313827\n",
      "Training loss: -0.0004324747271132331\n",
      "Training loss: -0.0004324419322693207\n",
      "Training loss: -0.0004324091409109282\n",
      "Training loss: -0.00043237635303757833\n",
      "Training loss: -0.0004323435686488006\n",
      "Training loss: -0.00043231078774411835\n",
      "Training loss: -0.00043227801032305835\n",
      "Training loss: -0.0004322452363851471\n",
      "Training loss: -0.00043221246592991196\n",
      "Training loss: -0.00043217969895687674\n",
      "Training loss: -0.00043214693546556764\n",
      "Training loss: -0.00043211417545551485\n",
      "Training loss: -0.00043208141892624\n",
      "Training loss: -0.0004320486658772736\n",
      "Training loss: -0.0004320159163081398\n",
      "Training loss: -0.0004319831702183675\n",
      "Training loss: -0.00043195042760748226\n",
      "Training loss: -0.0004319176884750095\n",
      "Training loss: -0.00043188495282047915\n",
      "Training loss: -0.00043185222064341547\n",
      "Training loss: -0.00043181949194334804\n",
      "Training loss: -0.00043178676671980226\n",
      "Training loss: -0.00043175404497230703\n",
      "Training loss: -0.0004317213267003878\n",
      "Training loss: -0.0004316886119035739\n",
      "Training loss: -0.00043165590058139096\n",
      "Training loss: -0.0004316231927333674\n",
      "Training loss: -0.00043159048835903234\n",
      "Training loss: -0.00043155778745791165\n",
      "Training loss: -0.00043152509002953367\n",
      "Training loss: -0.00043149239607342705\n",
      "Training loss: -0.00043145970558911847\n",
      "Training loss: -0.0004314270185761372\n",
      "Training loss: -0.00043139433503401007\n",
      "Training loss: -0.0004313616549622671\n",
      "Training loss: -0.00043132897836043615\n",
      "Training loss: -0.0004312963052280441\n",
      "Training loss: -0.0004312636355646205\n",
      "Training loss: -0.0004312309693696939\n",
      "Training loss: -0.0004311983066427919\n",
      "Training loss: -0.00043116564738344515\n",
      "Training loss: -0.0004311329915911802\n",
      "Training loss: -0.0004311003392655275\n",
      "Training loss: -0.00043106769040601565\n",
      "Training loss: -0.00043103504501217364\n",
      "Training loss: -0.0004310024030835305\n",
      "Training loss: -0.0004309697646196145\n",
      "Training loss: -0.0004309371296199565\n",
      "Training loss: -0.00043090449808408403\n",
      "Training loss: -0.0004308718700115276\n",
      "Training loss: -0.0004308392454018167\n",
      "Training loss: -0.0004308066242544796\n",
      "Training loss: -0.00043077400656904753\n",
      "Training loss: -0.00043074139234504914\n",
      "Training loss: -0.00043070878158201544\n",
      "Training loss: -0.0004306761742794756\n",
      "Training loss: -0.0004306435704369582\n",
      "Training loss: -0.0004306109700539943\n",
      "Training loss: -0.0004305783731301147\n",
      "Training loss: -0.0004305457796648493\n",
      "Training loss: -0.0004305131896577274\n",
      "Training loss: -0.00043048060310828034\n",
      "Training loss: -0.00043044802001603754\n",
      "Training loss: -0.00043041544038052953\n",
      "Training loss: -0.00043038286420128815\n",
      "Training loss: -0.00043035029147784254\n",
      "Training loss: -0.000430317722209725\n",
      "Training loss: -0.00043028515639646493\n",
      "Training loss: -0.0004302525940375931\n",
      "Training loss: -0.0004302200351326406\n",
      "Training loss: -0.00043018747968113813\n",
      "Training loss: -0.00043015492768261804\n",
      "Training loss: -0.0004301223791366105\n",
      "Training loss: -0.0004300898340426487\n",
      "Training loss: -0.0004300572924002615\n",
      "Training loss: -0.0004300247542089793\n",
      "Training loss: -0.0004299922194683381\n",
      "Training loss: -0.00042995968817786495\n",
      "Training loss: -0.00042992716033709384\n",
      "Training loss: -0.00042989463594555555\n",
      "Training loss: -0.0004298621150027819\n",
      "Training loss: -0.0004298295975083066\n",
      "Training loss: -0.00042979708346165837\n",
      "Training loss: -0.00042976457286237094\n",
      "Training loss: -0.0004297320657099763\n",
      "Training loss: -0.0004296995620040065\n",
      "Training loss: -0.0004296670617439946\n",
      "Training loss: -0.0004296345649294716\n",
      "Training loss: -0.0004296020715599707\n",
      "Training loss: -0.0004295695816350238\n",
      "Training loss: -0.00042953709515416343\n",
      "Training loss: -0.0004295046121169233\n",
      "Training loss: -0.00042947213252283556\n",
      "Training loss: -0.0004294396563714316\n",
      "Training loss: -0.0004294071836622459\n",
      "Training loss: -0.00042937471439481023\n",
      "Training loss: -0.00042934224856865837\n",
      "Training loss: -0.00042930978618332396\n",
      "Training loss: -0.0004292773272383399\n",
      "Training loss: -0.0004292448717332391\n",
      "Training loss: -0.00042921241966755293\n",
      "Training loss: -0.00042917997104081743\n",
      "Training loss: -0.00042914752585256603\n",
      "Training loss: -0.00042911508410232974\n",
      "Training loss: -0.00042908264578964524\n",
      "Training loss: -0.0004290502109140445\n",
      "Training loss: -0.00042901777947506215\n",
      "Training loss: -0.00042898535147223006\n",
      "Training loss: -0.0004289529269050854\n",
      "Training loss: -0.00042892050577316045\n",
      "Training loss: -0.00042888808807598893\n",
      "Training loss: -0.0004288556738131036\n",
      "Training loss: -0.0004288232629840424\n",
      "Training loss: -0.0004287908555883365\n",
      "Training loss: -0.00042875845162552333\n",
      "Training loss: -0.00042872605109513413\n",
      "Training loss: -0.00042869365399670413\n",
      "Training loss: -0.0004286612603297685\n",
      "Training loss: -0.0004286288700938634\n",
      "Training loss: -0.0004285964832885211\n",
      "Training loss: -0.00042856409991327745\n",
      "Training loss: -0.0004285317199676684\n",
      "Training loss: -0.0004284993434512267\n",
      "Training loss: -0.0004284669703634894\n",
      "Training loss: -0.0004284346007039906\n",
      "Training loss: -0.0004284022344722658\n",
      "Training loss: -0.00042836987166785037\n",
      "Training loss: -0.0004283375122902802\n",
      "Training loss: -0.000428305156339088\n",
      "Training loss: -0.0004282728038138127\n",
      "Training loss: -0.0004282404547139895\n",
      "Training loss: -0.00042820810903915234\n",
      "Training loss: -0.00042817576678883846\n",
      "Training loss: -0.0004281434279625816\n",
      "Training loss: -0.00042811109255992035\n",
      "Training loss: -0.0004280787605803888\n",
      "Training loss: -0.0004280464320235245\n",
      "Training loss: -0.0004280141068888627\n",
      "Training loss: -0.00042798178517593926\n",
      "Training loss: -0.00042794946688429035\n",
      "Training loss: -0.00042791715201345357\n",
      "Training loss: -0.0004278848405629656\n",
      "Training loss: -0.00042785253253236027\n",
      "Training loss: -0.0004278202279211774\n",
      "Training loss: -0.0004277879267289524\n",
      "Training loss: -0.0004277556289552202\n",
      "Training loss: -0.00042772333459951934\n",
      "Training loss: -0.00042769104366138615\n",
      "Training loss: -0.00042765875614035837\n",
      "Training loss: -0.00042762647203597315\n",
      "Training loss: -0.0004275941913477661\n",
      "Training loss: -0.0004275619140752769\n",
      "Training loss: -0.00042752964021803896\n",
      "Training loss: -0.00042749736977559474\n",
      "Training loss: -0.00042746510274747733\n",
      "Training loss: -0.00042743283913322606\n",
      "Training loss: -0.00042740057893237885\n",
      "Training loss: -0.0004273683221444719\n",
      "Training loss: -0.0004273360687690448\n",
      "Training loss: -0.0004273038188056346\n",
      "Training loss: -0.00042727157225377844\n",
      "Training loss: -0.00042723932911301396\n",
      "Training loss: -0.0004272070893828795\n",
      "Training loss: -0.0004271748530629164\n",
      "Training loss: -0.00042714262015265805\n",
      "Training loss: -0.00042711039065164663\n",
      "Training loss: -0.00042707816455941737\n",
      "Training loss: -0.0004270459418755089\n",
      "Training loss: -0.00042701372259946227\n",
      "Training loss: -0.00042698150673081274\n",
      "Training loss: -0.00042694929426910185\n",
      "Training loss: -0.00042691708521386815\n",
      "Training loss: -0.0004268848795646475\n",
      "Training loss: -0.00042685267732098275\n",
      "Training loss: -0.00042682047848240936\n",
      "Training loss: -0.0004267882830484683\n",
      "Training loss: -0.0004267560910186979\n",
      "Training loss: -0.00042672390239263696\n",
      "Training loss: -0.0004266917171698261\n",
      "Training loss: -0.00042665953534980433\n",
      "Training loss: -0.0004266273569321093\n",
      "Training loss: -0.00042659518191628156\n",
      "Training loss: -0.0004265630103018617\n",
      "Training loss: -0.000426530842088389\n",
      "Training loss: -0.0004264986772754012\n",
      "Training loss: -0.0004264665158624407\n",
      "Training loss: -0.00042643435784904543\n",
      "Training loss: -0.000426402203234755\n",
      "Training loss: -0.00042637005201911165\n",
      "Training loss: -0.00042633790420165246\n",
      "Training loss: -0.00042630575978192084\n",
      "Training loss: -0.0004262736187594557\n",
      "Training loss: -0.0004262414811337975\n",
      "Training loss: -0.0004262093469044853\n",
      "Training loss: -0.00042617721607106064\n",
      "Training loss: -0.0004261450886330642\n",
      "Training loss: -0.0004261129645900351\n",
      "Training loss: -0.0004260808439415162\n",
      "Training loss: -0.00042604872668704615\n",
      "Training loss: -0.00042601661282616675\n",
      "Training loss: -0.0004259845023584195\n",
      "Training loss: -0.0004259523952833443\n",
      "Training loss: -0.00042592029160048404\n",
      "Training loss: -0.000425888191309377\n",
      "Training loss: -0.00042585609440956655\n",
      "Training loss: -0.00042582400090059253\n",
      "Training loss: -0.00042579191078199763\n",
      "Training loss: -0.0004257598240533227\n",
      "Training loss: -0.00042572774071410885\n",
      "Training loss: -0.0004256956607638978\n",
      "Training loss: -0.00042566358420223217\n",
      "Training loss: -0.0004256315110286531\n",
      "Training loss: -0.00042559944124270115\n",
      "Training loss: -0.0004255673748439204\n",
      "Training loss: -0.00042553531183185043\n",
      "Training loss: -0.0004255032522060356\n",
      "Training loss: -0.000425471195966017\n",
      "Training loss: -0.0004254391431113357\n",
      "Training loss: -0.0004254070936415346\n",
      "Training loss: -0.000425375047556158\n",
      "Training loss: -0.0004253430048547459\n",
      "Training loss: -0.0004253109655368412\n",
      "Training loss: -0.00042527892960198715\n",
      "Training loss: -0.0004252468970497264\n",
      "Training loss: -0.00042521486787959874\n",
      "Training loss: -0.0004251828420911521\n",
      "Training loss: -0.0004251508196839257\n",
      "Training loss: -0.0004251188006574641\n",
      "Training loss: -0.00042508678501130724\n",
      "Training loss: -0.00042505477274500293\n",
      "Training loss: -0.0004250227638580903\n",
      "Training loss: -0.000424990758350115\n",
      "Training loss: -0.0004249587562206192\n",
      "Training loss: -0.0004249267574691471\n",
      "Training loss: -0.0004248947620952416\n",
      "Training loss: -0.00042486277009844565\n",
      "Training loss: -0.00042483078147830303\n",
      "Training loss: -0.0004247987962343577\n",
      "Training loss: -0.00042476681436615473\n",
      "Training loss: -0.0004247348358732357\n",
      "Training loss: -0.0004247028607551459\n",
      "Training loss: -0.00042467088901142924\n",
      "Training loss: -0.0004246389206416288\n",
      "Training loss: -0.00042460695564528936\n",
      "Training loss: -0.0004245749940219555\n",
      "Training loss: -0.00042454303577116987\n",
      "Training loss: -0.00042451108089247764\n",
      "Training loss: -0.0004244791293854249\n",
      "Training loss: -0.00042444718124955345\n",
      "Training loss: -0.00042441523648441065\n",
      "Training loss: -0.0004243832950895397\n",
      "Training loss: -0.00042435135706448427\n",
      "Training loss: -0.00042431942240879017\n",
      "Training loss: -0.0004242874911220039\n",
      "Training loss: -0.0004242555632036671\n",
      "Training loss: -0.00042422363865332727\n",
      "Training loss: -0.000424191717470528\n",
      "Training loss: -0.0004241597996548145\n",
      "Training loss: -0.00042412788520573223\n",
      "Training loss: -0.0004240959741228279\n",
      "Training loss: -0.00042406406640564567\n",
      "Training loss: -0.00042403216205373206\n",
      "Training loss: -0.00042400026106663007\n",
      "Training loss: -0.0004239683634438876\n",
      "Training loss: -0.00042393646918504897\n",
      "Training loss: -0.000423904578289662\n",
      "Training loss: -0.0004238726907572691\n",
      "Training loss: -0.0004238408065874192\n",
      "Training loss: -0.0004238089257796571\n",
      "Training loss: -0.0004237770483335299\n",
      "Training loss: -0.00042374517424858247\n",
      "Training loss: -0.0004237133035243615\n",
      "Training loss: -0.0004236814361604132\n",
      "Training loss: -0.00042364957215628254\n",
      "Training loss: -0.00042361771151151783\n",
      "Training loss: -0.00042358585422566463\n",
      "Training loss: -0.00042355400029826974\n",
      "Training loss: -0.00042352214972888013\n",
      "Training loss: -0.0004234903025170428\n",
      "Training loss: -0.0004234584586623036\n",
      "Training loss: -0.0004234266181642096\n",
      "Training loss: -0.0004233947810223079\n",
      "Training loss: -0.0004233629472361461\n",
      "Training loss: -0.0004233311168052687\n",
      "Training loss: -0.0004232992897292268\n",
      "Training loss: -0.0004232674660075641\n",
      "Training loss: -0.00042323564563983104\n",
      "Training loss: -0.0004232038286255731\n",
      "Training loss: -0.0004231720149643387\n",
      "Training loss: -0.0004231402046556737\n",
      "Training loss: -0.0004231083976991262\n",
      "Training loss: -0.00042307659409424617\n",
      "Training loss: -0.00042304479384057923\n",
      "Training loss: -0.00042301299693767316\n",
      "Training loss: -0.00042298120338507615\n",
      "Training loss: -0.000422949413182336\n",
      "Training loss: -0.00042291762632900063\n",
      "Training loss: -0.00042288584282461973\n",
      "Training loss: -0.0004228540626687405\n",
      "Training loss: -0.0004228222858609096\n",
      "Training loss: -0.0004227905124006783\n",
      "Training loss: -0.00042275874228759144\n",
      "Training loss: -0.0004227269755212011\n",
      "Training loss: -0.0004226952121010542\n",
      "Training loss: -0.0004226634520266994\n",
      "Training loss: -0.0004226316952976849\n",
      "Training loss: -0.00042259994191356045\n",
      "Training loss: -0.00042256819187387466\n",
      "Training loss: -0.000422536445178176\n",
      "Training loss: -0.00042250470182601444\n",
      "Training loss: -0.00042247296181693774\n",
      "Training loss: -0.000422441225150497\n",
      "Training loss: -0.0004224094918262395\n",
      "Training loss: -0.00042237776184371483\n",
      "Training loss: -0.00042234603520247173\n",
      "Training loss: -0.00042231431190206225\n",
      "Training loss: -0.000422282591942034\n",
      "Training loss: -0.00042225087532193623\n",
      "Training loss: -0.00042221916204131916\n",
      "Training loss: -0.0004221874520997326\n",
      "Training loss: -0.00042215574549672627\n",
      "Training loss: -0.00042212404223185057\n",
      "Training loss: -0.00042209234230465456\n",
      "Training loss: -0.00042206064571468954\n",
      "Training loss: -0.00042202895246150395\n",
      "Training loss: -0.00042199726254465054\n",
      "Training loss: -0.00042196557596367563\n",
      "Training loss: -0.00042193389271813296\n",
      "Training loss: -0.0004219022128075718\n",
      "Training loss: -0.0004218705362315416\n",
      "Training loss: -0.000421838862989594\n",
      "Training loss: -0.0004218071930812802\n",
      "Training loss: -0.0004217755265061486\n",
      "Training loss: -0.00042174386326375245\n",
      "Training loss: -0.0004217122033536417\n",
      "Training loss: -0.00042168054677536746\n",
      "Training loss: -0.00042164889352847956\n",
      "Training loss: -0.0004216172436125303\n",
      "Training loss: -0.0004215855970270702\n",
      "Training loss: -0.00042155395377165206\n",
      "Training loss: -0.0004215223138458244\n",
      "Training loss: -0.0004214906772491398\n",
      "Training loss: -0.0004214590439811506\n",
      "Training loss: -0.0004214274140414088\n",
      "Training loss: -0.0004213957874294632\n",
      "Training loss: -0.0004213641641448669\n",
      "Training loss: -0.000421332544187173\n",
      "Training loss: -0.0004213009275559301\n",
      "Training loss: -0.0004212693142506935\n",
      "Training loss: -0.00042123770427101323\n",
      "Training loss: -0.00042120609761644176\n",
      "Training loss: -0.00042117449428653067\n",
      "Training loss: -0.00042114289428083233\n",
      "Training loss: -0.0004211112975988987\n",
      "Training loss: -0.0004210797042402835\n",
      "Training loss: -0.0004210481142045374\n",
      "Training loss: -0.0004210165274912131\n",
      "Training loss: -0.0004209849440998652\n",
      "Training loss: -0.0004209533640300428\n",
      "Training loss: -0.0004209217872813018\n",
      "Training loss: -0.00042089021385319247\n",
      "Training loss: -0.0004208586437452696\n",
      "Training loss: -0.000420827076957085\n",
      "Training loss: -0.00042079551348819154\n",
      "Training loss: -0.0004207639533381428\n",
      "Training loss: -0.00042073239650649083\n",
      "Training loss: -0.0004207008429927895\n",
      "Training loss: -0.00042066929279659343\n",
      "Training loss: -0.00042063774591745396\n",
      "Training loss: -0.0004206062023549244\n",
      "Training loss: -0.0004205746621085594\n",
      "Training loss: -0.0004205431251779118\n",
      "Training loss: -0.00042051159156253554\n",
      "Training loss: -0.0004204800612619846\n",
      "Training loss: -0.00042044853427581226\n",
      "Training loss: -0.00042041701060357257\n",
      "Training loss: -0.00042038549024482\n",
      "Training loss: -0.0004203539731991057\n",
      "Training loss: -0.0004203224594659869\n",
      "Training loss: -0.000420290949045016\n",
      "Training loss: -0.0004202594419357487\n",
      "Training loss: -0.0004202279381377383\n",
      "Training loss: -0.00042019643765053865\n",
      "Training loss: -0.0004201649404737051\n",
      "Training loss: -0.00042013344660679283\n",
      "Training loss: -0.00042010195604935436\n",
      "Training loss: -0.00042007046880094574\n",
      "Training loss: -0.0004200389848611218\n",
      "Training loss: -0.00042000750422943475\n",
      "Training loss: -0.0004199760269054438\n",
      "Training loss: -0.00041994455288870016\n",
      "Training loss: -0.00041991308217876044\n",
      "Training loss: -0.00041988161477517986\n",
      "Training loss: -0.00041985015067751174\n",
      "Training loss: -0.00041981868988531345\n",
      "Training loss: -0.0004197872323981392\n",
      "Training loss: -0.00041975577821554394\n",
      "Training loss: -0.00041972432733708507\n",
      "Training loss: -0.0004196928797623174\n",
      "Training loss: -0.00041966143549079446\n",
      "Training loss: -0.00041962999452207383\n",
      "Training loss: -0.0004195985568557103\n",
      "Training loss: -0.0004195671224912592\n",
      "Training loss: -0.0004195356914282793\n",
      "Training loss: -0.000419504263666322\n",
      "Training loss: -0.0004194728392049475\n",
      "Training loss: -0.0004194414180437089\n",
      "Training loss: -0.00041941000018216504\n",
      "Training loss: -0.00041937858561987034\n",
      "Training loss: -0.0004193471743563814\n",
      "Training loss: -0.0004193157663912537\n",
      "Training loss: -0.00041928436172404554\n",
      "Training loss: -0.00041925296035431214\n",
      "Training loss: -0.00041922156228160984\n",
      "Training loss: -0.0004191901675054967\n",
      "Training loss: -0.0004191587760255294\n",
      "Training loss: -0.0004191273878412619\n",
      "Training loss: -0.00041909600295225496\n",
      "Training loss: -0.00041906462135806225\n",
      "Training loss: -0.0004190332430582434\n",
      "Training loss: -0.00041900186805235185\n",
      "Training loss: -0.0004189704963399493\n",
      "Training loss: -0.0004189391279205904\n",
      "Training loss: -0.0004189077627938342\n",
      "Training loss: -0.0004188764009592359\n",
      "Training loss: -0.00041884504241635265\n",
      "Training loss: -0.0004188136871647442\n",
      "Training loss: -0.0004187823352039662\n",
      "Training loss: -0.0004187509865335786\n",
      "Training loss: -0.00041871964115313624\n",
      "Training loss: -0.0004186882990622\n",
      "Training loss: -0.0004186569602603246\n",
      "Training loss: -0.00041862562474707113\n",
      "Training loss: -0.0004185942925219951\n",
      "Training loss: -0.0004185629635846551\n",
      "Training loss: -0.0004185316379346105\n",
      "Training loss: -0.00041850031557141837\n",
      "Training loss: -0.00041846899649463834\n",
      "Training loss: -0.0004184376807038268\n",
      "Training loss: -0.0004184063681985444\n",
      "Training loss: -0.0004183750589783472\n",
      "Training loss: -0.00041834375304279517\n",
      "Training loss: -0.00041831245039144707\n",
      "Training loss: -0.0004182811510238624\n",
      "Training loss: -0.0004182498549395981\n",
      "Training loss: -0.0004182185621382142\n",
      "Training loss: -0.0004181872726192693\n",
      "Training loss: -0.0004181559863823239\n",
      "Training loss: -0.0004181247034269344\n",
      "Training loss: -0.00041809342375266097\n",
      "Training loss: -0.0004180621473590645\n",
      "Training loss: -0.0004180308742457029\n",
      "Training loss: -0.0004179996044121335\n",
      "Training loss: -0.00041796833785792\n",
      "Training loss: -0.00041793707458262047\n",
      "Training loss: -0.0004179058145857931\n",
      "Training loss: -0.0004178745578669983\n",
      "Training loss: -0.0004178433044257964\n",
      "Training loss: -0.00041781205426174635\n",
      "Training loss: -0.0004177808073744082\n",
      "Training loss: -0.0004177495637633413\n",
      "Training loss: -0.00041771832342810713\n",
      "Training loss: -0.0004176870863682652\n",
      "Training loss: -0.00041765585258337576\n",
      "Training loss: -0.0004176246220729985\n",
      "Training loss: -0.000417593394836695\n",
      "Training loss: -0.00041756217087402376\n",
      "Training loss: -0.00041753095018454644\n",
      "Training loss: -0.0004174997327678231\n",
      "Training loss: -0.0004174685186234155\n",
      "Training loss: -0.0004174373077508824\n",
      "Training loss: -0.0004174061001497844\n",
      "Training loss: -0.00041737489581968566\n",
      "Training loss: -0.000417343694760143\n",
      "Training loss: -0.0004173124969707204\n",
      "Training loss: -0.00041728130245097765\n",
      "Training loss: -0.00041725011120047643\n",
      "Training loss: -0.00041721892321877624\n",
      "Training loss: -0.0004171877385054407\n",
      "Training loss: -0.0004171565570600289\n",
      "Training loss: -0.0004171253788821034\n",
      "Training loss: -0.0004170942039712263\n",
      "Training loss: -0.00041706303232695726\n",
      "Training loss: -0.00041703186394885885\n",
      "Training loss: -0.00041700069883649334\n",
      "Training loss: -0.0004169695369894206\n",
      "Training loss: -0.00041693837840720455\n",
      "Training loss: -0.0004169072230894064\n",
      "Training loss: -0.0004168760710355887\n",
      "Training loss: -0.000416844922245312\n",
      "Training loss: -0.00041681377671813863\n",
      "Training loss: -0.00041678263445363067\n",
      "Training loss: -0.0004167514954513525\n",
      "Training loss: -0.0004167203597108644\n",
      "Training loss: -0.0004166892272317286\n",
      "Training loss: -0.00041665809801350875\n",
      "Training loss: -0.000416626972055766\n",
      "Training loss: -0.0004165958493580641\n",
      "Training loss: -0.0004165647299199659\n",
      "Training loss: -0.00041653361374103354\n",
      "Training loss: -0.0004165025008208302\n",
      "Training loss: -0.0004164713911589171\n",
      "Training loss: -0.0004164402847548588\n",
      "Training loss: -0.00041640918160822\n",
      "Training loss: -0.000416378081718559\n",
      "Training loss: -0.00041634698508544366\n",
      "Training loss: -0.0004163158917084351\n",
      "Training loss: -0.0004162848015870965\n",
      "Training loss: -0.00041625371472099116\n",
      "Training loss: -0.00041622263110968366\n",
      "Training loss: -0.0004161915507527366\n",
      "Training loss: -0.00041616047364971304\n",
      "Training loss: -0.00041612939980017674\n",
      "Training loss: -0.0004160983292036935\n",
      "Training loss: -0.00041606726185982565\n",
      "Training loss: -0.0004160361977681353\n",
      "Training loss: -0.0004160051369281901\n",
      "Training loss: -0.0004159740793395507\n",
      "Training loss: -0.0004159430250017841\n",
      "Training loss: -0.0004159119739144521\n",
      "Training loss: -0.0004158809260771207\n",
      "Training loss: -0.0004158498814893529\n",
      "Training loss: -0.0004158188401507123\n",
      "Training loss: -0.00041578780206076577\n",
      "Training loss: -0.00041575676721907596\n",
      "Training loss: -0.0004157257356252071\n",
      "Training loss: -0.00041569470727872564\n",
      "Training loss: -0.00041566368217919517\n",
      "Training loss: -0.0004156326603261805\n",
      "Training loss: -0.00041560164171924673\n",
      "Training loss: -0.00041557062635795935\n",
      "Training loss: -0.0004155396142418815\n",
      "Training loss: -0.0004155086053705798\n",
      "Training loss: -0.00041547759974361873\n",
      "Training loss: -0.0004154465973605643\n",
      "Training loss: -0.00041541559822098217\n",
      "Training loss: -0.0004153846023244362\n",
      "Training loss: -0.0004153536096704922\n",
      "Training loss: -0.00041532262025871644\n",
      "Training loss: -0.0004152916340886726\n",
      "Training loss: -0.0004152606511599287\n",
      "Training loss: -0.0004152296714720492\n",
      "Training loss: -0.0004151986950245995\n",
      "Training loss: -0.00041516772181714694\n",
      "Training loss: -0.00041513675184925617\n",
      "Training loss: -0.0004151057851204929\n",
      "Training loss: -0.0004150748216304235\n",
      "Training loss: -0.00041504386137861354\n",
      "Training loss: -0.0004150129043646322\n",
      "Training loss: -0.0004149819505880439\n",
      "Training loss: -0.0004149510000484137\n",
      "Training loss: -0.0004149200527453082\n",
      "Training loss: -0.00041488910867829574\n",
      "Training loss: -0.00041485816784694055\n",
      "Training loss: -0.00041482723025081173\n",
      "Training loss: -0.000414796295889474\n",
      "Training loss: -0.0004147653647624955\n",
      "Training loss: -0.0004147344368694416\n",
      "Training loss: -0.0004147035122098804\n",
      "Training loss: -0.0004146725907833794\n",
      "Training loss: -0.0004146416725895022\n",
      "Training loss: -0.0004146107576278204\n",
      "Training loss: -0.0004145798458978969\n",
      "Training loss: -0.00041454893739930416\n",
      "Training loss: -0.00041451803213160505\n",
      "Training loss: -0.0004144871300943693\n",
      "Training loss: -0.00041445623128716304\n",
      "Training loss: -0.000414425335709553\n",
      "Training loss: -0.0004143944433611092\n",
      "Training loss: -0.00041436355424139784\n",
      "Training loss: -0.0004143326683499872\n",
      "Training loss: -0.00041430178568644484\n",
      "Training loss: -0.0004142709062503385\n",
      "Training loss: -0.0004142400300412366\n",
      "Training loss: -0.00041420915705870574\n",
      "Training loss: -0.0004141782873023171\n",
      "Training loss: -0.0004141474207716361\n",
      "Training loss: -0.0004141165574662329\n",
      "Training loss: -0.00041408569738567266\n",
      "Training loss: -0.0004140548405295262\n",
      "Training loss: -0.0004140239868973624\n",
      "Training loss: -0.000413993136488748\n",
      "Training loss: -0.0004139622893032525\n",
      "Training loss: -0.00041393144534044495\n",
      "Training loss: -0.0004139006045998937\n",
      "Training loss: -0.000413869767081166\n",
      "Training loss: -0.00041383893278383344\n",
      "Training loss: -0.00041380810170746444\n",
      "Training loss: -0.00041377727385162507\n",
      "Training loss: -0.0004137464492158888\n",
      "Training loss: -0.0004137156277998215\n",
      "Training loss: -0.000413684809602993\n",
      "Training loss: -0.00041365399462497433\n",
      "Training loss: -0.00041362318286533193\n",
      "Training loss: -0.0004135923743236369\n",
      "Training loss: -0.00041356156899945926\n",
      "Training loss: -0.0004135307668923669\n",
      "Training loss: -0.0004134999680019309\n",
      "Training loss: -0.00041346917232772145\n",
      "Training loss: -0.0004134383798693063\n",
      "Training loss: -0.0004134075906262561\n",
      "Training loss: -0.0004133768045981414\n",
      "Training loss: -0.00041334602178453173\n",
      "Training loss: -0.00041331524218499714\n",
      "Training loss: -0.000413284465799108\n",
      "Training loss: -0.000413253692626434\n",
      "Training loss: -0.0004132229226665449\n",
      "Training loss: -0.0004131921559190123\n",
      "Training loss: -0.0004131613923834064\n",
      "Training loss: -0.0004131306320592972\n",
      "Training loss: -0.0004130998749462555\n",
      "Training loss: -0.0004130691210438511\n",
      "Training loss: -0.0004130383703516547\n",
      "Training loss: -0.000413007622869239\n",
      "Training loss: -0.00041297687859617374\n",
      "Training loss: -0.0004129461375320285\n",
      "Training loss: -0.00041291539967637536\n",
      "Training loss: -0.0004128846650287848\n",
      "Training loss: -0.0004128539335888283\n",
      "Training loss: -0.0004128232053560775\n",
      "Training loss: -0.00041279248033010386\n",
      "Training loss: -0.0004127617585104763\n",
      "Training loss: -0.000412731039896769\n",
      "Training loss: -0.0004127003244885521\n",
      "Training loss: -0.0004126696122853981\n",
      "Training loss: -0.0004126389032868753\n",
      "Training loss: -0.0004126081974925596\n",
      "Training loss: -0.0004125774949020205\n",
      "Training loss: -0.00041254679551483057\n",
      "Training loss: -0.0004125160993305603\n",
      "Training loss: -0.00041248540634878245\n",
      "Training loss: -0.00041245471656906887\n",
      "Training loss: -0.00041242402999099194\n",
      "Training loss: -0.00041239334661412303\n",
      "Training loss: -0.0004123626664380359\n",
      "Training loss: -0.0004123319894623026\n",
      "Training loss: -0.00041230131568649366\n",
      "Training loss: -0.000412270645110183\n",
      "Training loss: -0.0004122399777329433\n",
      "Training loss: -0.0004122093135543454\n",
      "Training loss: -0.0004121786525739634\n",
      "Training loss: -0.0004121479947913702\n",
      "Training loss: -0.0004121173402061354\n",
      "Training loss: -0.00041208668881783733\n",
      "Training loss: -0.00041205604062604485\n",
      "Training loss: -0.00041202539563033074\n",
      "Training loss: -0.0004119947538302694\n",
      "Training loss: -0.0004119641152254337\n",
      "Training loss: -0.0004119334798153969\n",
      "Training loss: -0.000411902847599733\n",
      "Training loss: -0.00041187221857801536\n",
      "Training loss: -0.00041184159274981465\n",
      "Training loss: -0.00041181097011470686\n",
      "Training loss: -0.000411780350672265\n",
      "Training loss: -0.00041174973442206135\n",
      "Training loss: -0.00041171912136367205\n",
      "Training loss: -0.0004116885114966678\n",
      "Training loss: -0.0004116579048206248\n",
      "Training loss: -0.00041162730133511536\n",
      "Training loss: -0.0004115967010397146\n",
      "Training loss: -0.0004115661039339947\n",
      "Training loss: -0.00041153551001753107\n",
      "Training loss: -0.0004115049192898984\n",
      "Training loss: -0.0004114743317506706\n",
      "Training loss: -0.0004114437473994208\n",
      "Training loss: -0.0004114131662357252\n",
      "Training loss: -0.0004113825882591555\n",
      "Training loss: -0.00041135201346928897\n",
      "Training loss: -0.0004113214418656985\n",
      "Training loss: -0.0004112908734479587\n",
      "Training loss: -0.0004112603082156451\n",
      "Training loss: -0.00041122974616833235\n",
      "Training loss: -0.0004111991873055946\n",
      "Training loss: -0.0004111686316270068\n",
      "Training loss: -0.00041113807913214384\n",
      "Training loss: -0.0004111075298205824\n",
      "Training loss: -0.00041107698369189543\n",
      "Training loss: -0.00041104644074565897\n",
      "Training loss: -0.00041101590098144785\n",
      "Training loss: -0.0004109853643988368\n",
      "Training loss: -0.0004109548309974041\n",
      "Training loss: -0.0004109243007767214\n",
      "Training loss: -0.00041089377373636736\n",
      "Training loss: -0.00041086324987591545\n",
      "Training loss: -0.00041083272919494084\n",
      "Training loss: -0.0004108022116930213\n",
      "Training loss: -0.000410771697369732\n",
      "Training loss: -0.000410741186224648\n",
      "Training loss: -0.00041071067825734493\n",
      "Training loss: -0.00041068017346740143\n",
      "Training loss: -0.0004106496718543895\n",
      "Training loss: -0.0004106191734178882\n",
      "Training loss: -0.00041058867815747335\n",
      "Training loss: -0.0004105581860727203\n",
      "Training loss: -0.0004105276971632058\n",
      "Training loss: -0.00041049721142850574\n",
      "Training loss: -0.0004104667288681971\n",
      "Training loss: -0.00041043624948185697\n",
      "Training loss: -0.00041040577326906106\n",
      "Training loss: -0.00041037530022938507\n",
      "Training loss: -0.0004103448303624085\n",
      "Training loss: -0.0004103143636677073\n",
      "Training loss: -0.0004102839001448559\n",
      "Training loss: -0.00041025343979343514\n",
      "Training loss: -0.00041022298261301875\n",
      "Training loss: -0.00041019252860318404\n",
      "Training loss: -0.00041016207776351025\n",
      "Training loss: -0.00041013163009357356\n",
      "Training loss: -0.00041010118559294895\n",
      "Training loss: -0.00041007074426121685\n",
      "Training loss: -0.00041004030609795473\n",
      "Training loss: -0.00041000987110273874\n",
      "Training loss: -0.0004099794392751471\n",
      "Training loss: -0.00040994901061475555\n",
      "Training loss: -0.0004099185851211435\n",
      "Training loss: -0.0004098881627938898\n",
      "Training loss: -0.0004098577436325707\n",
      "Training loss: -0.00040982732763676394\n",
      "Training loss: -0.0004097969148060483\n",
      "Training loss: -0.0004097665051400001\n",
      "Training loss: -0.0004097360986382002\n",
      "Training loss: -0.000409705695300225\n",
      "Training loss: -0.00040967529512565284\n",
      "Training loss: -0.0004096448981140631\n",
      "Training loss: -0.0004096145042650324\n",
      "Training loss: -0.00040958411357814103\n",
      "Training loss: -0.00040955372605296607\n",
      "Training loss: -0.0004095233416890855\n",
      "Training loss: -0.00040949296048607876\n",
      "Training loss: -0.00040946258244352676\n",
      "Training loss: -0.00040943220756100467\n",
      "Training loss: -0.00040940183583809274\n",
      "Training loss: -0.00040937146727437133\n",
      "Training loss: -0.00040934110186941695\n",
      "Training loss: -0.0004093107396228109\n",
      "Training loss: -0.0004092803805341304\n",
      "Training loss: -0.00040925002460295666\n",
      "Training loss: -0.00040921967182886674\n",
      "Training loss: -0.0004091893222114413\n",
      "Training loss: -0.00040915897575025936\n",
      "Training loss: -0.0004091286324449007\n",
      "Training loss: -0.0004090982922949434\n",
      "Training loss: -0.0004090679552999699\n",
      "Training loss: -0.0004090376214595581\n",
      "Training loss: -0.0004090072907732864\n",
      "Training loss: -0.00040897696324073736\n",
      "Training loss: -0.00040894663886148914\n",
      "Training loss: -0.00040891631763512187\n",
      "Training loss: -0.0004088859995612155\n",
      "Training loss: -0.0004088556846393496\n",
      "Training loss: -0.000408825372869107\n",
      "Training loss: -0.0004087950642500638\n",
      "Training loss: -0.0004087647587818029\n",
      "Training loss: -0.0004087344564639038\n",
      "Training loss: -0.0004087041572959487\n",
      "Training loss: -0.00040867386127751515\n",
      "Training loss: -0.00040864356840818595\n",
      "Training loss: -0.0004086132786875401\n",
      "Training loss: -0.00040858299211515815\n",
      "Training loss: -0.00040855270869062215\n",
      "Training loss: -0.0004085224284135119\n",
      "Training loss: -0.00040849215128340994\n",
      "Training loss: -0.00040846187729989657\n",
      "Training loss: -0.0004084316064625515\n",
      "Training loss: -0.00040840133877095765\n",
      "Training loss: -0.0004083710742246939\n",
      "Training loss: -0.0004083408128233431\n",
      "Training loss: -0.0004083105545664852\n",
      "Training loss: -0.00040828029945370366\n",
      "Training loss: -0.0004082500474845782\n",
      "Training loss: -0.0004082197986586913\n",
      "Training loss: -0.00040818955297562394\n",
      "Training loss: -0.00040815931043495753\n",
      "Training loss: -0.00040812907103627443\n",
      "Training loss: -0.0004080988347791559\n",
      "Training loss: -0.0004080686016631834\n",
      "Training loss: -0.00040803837168793987\n",
      "Training loss: -0.0004080081448530053\n",
      "Training loss: -0.0004079779211579637\n",
      "Training loss: -0.000407947700602398\n",
      "Training loss: -0.00040791748318588756\n",
      "Training loss: -0.000407887268908016\n",
      "Training loss: -0.00040785705776836547\n",
      "Training loss: -0.0004078268497665178\n",
      "Training loss: -0.00040779664490205725\n",
      "Training loss: -0.0004077664431745646\n",
      "Training loss: -0.0004077362445836242\n",
      "Training loss: -0.0004077060491288159\n",
      "Training loss: -0.0004076758568097226\n",
      "Training loss: -0.0004076456676259304\n",
      "Training loss: -0.00040761548157701915\n",
      "Training loss: -0.00040758529866257326\n",
      "Training loss: -0.00040755511888217405\n",
      "Training loss: -0.0004075249422354064\n",
      "Training loss: -0.0004074947687218528\n",
      "Training loss: -0.0004074645983410952\n",
      "Training loss: -0.000407434431092718\n",
      "Training loss: -0.00040740426697630477\n",
      "Training loss: -0.00040737410599143834\n",
      "Training loss: -0.0004073439481377021\n",
      "Training loss: -0.0004073137934146806\n",
      "Training loss: -0.0004072836418219551\n",
      "Training loss: -0.0004072534933591113\n",
      "Training loss: -0.000407223348025733\n",
      "Training loss: -0.0004071932058214019\n",
      "Training loss: -0.000407163066745704\n",
      "Training loss: -0.00040713293079822196\n",
      "Training loss: -0.0004071027979785389\n",
      "Training loss: -0.00040707266828624196\n",
      "Training loss: -0.00040704254172091296\n",
      "Training loss: -0.0004070124182821354\n",
      "Training loss: -0.0004069822979694948\n",
      "Training loss: -0.0004069521807825748\n",
      "Training loss: -0.00040692206672096143\n",
      "Training loss: -0.00040689195578423777\n",
      "Training loss: -0.000406861847971988\n",
      "Training loss: -0.00040683174328379695\n",
      "Training loss: -0.0004068016417192489\n",
      "Training loss: -0.00040677154327793045\n",
      "Training loss: -0.00040674144795942423\n",
      "Training loss: -0.0004067113557633155\n",
      "Training loss: -0.0004066812666891901\n",
      "Training loss: -0.0004066511807366312\n",
      "Training loss: -0.0004066210979052264\n",
      "Training loss: -0.0004065910181945595\n",
      "Training loss: -0.0004065609416042164\n",
      "Training loss: -0.0004065308681337795\n",
      "Training loss: -0.0004065007977828375\n",
      "Training loss: -0.0004064707305509747\n",
      "Training loss: -0.0004064406664377753\n",
      "Training loss: -0.0004064106054428257\n",
      "Training loss: -0.0004063805475657118\n",
      "Training loss: -0.0004063504928060192\n",
      "Training loss: -0.00040632044116333346\n",
      "Training loss: -0.0004062903926372411\n",
      "Training loss: -0.00040626034722732613\n",
      "Training loss: -0.0004062303049331761\n",
      "Training loss: -0.00040620026575437554\n",
      "Training loss: -0.000406170229690512\n",
      "Training loss: -0.0004061401967411714\n",
      "Training loss: -0.0004061101669059377\n",
      "Training loss: -0.0004060801401844007\n",
      "Training loss: -0.00040605011657614384\n",
      "Training loss: -0.0004060200960807543\n",
      "Training loss: -0.0004059900786978201\n",
      "Training loss: -0.00040596006442692465\n",
      "Training loss: -0.00040593005326765747\n",
      "Training loss: -0.0004059000452196023\n",
      "Training loss: -0.0004058700402823486\n",
      "Training loss: -0.0004058400384554822\n",
      "Training loss: -0.00040581003973858974\n",
      "Training loss: -0.00040578004413125817\n",
      "Training loss: -0.00040575005163307284\n",
      "Training loss: -0.00040572006224362354\n",
      "Training loss: -0.00040569007596249644\n",
      "Training loss: -0.00040566009278927796\n",
      "Training loss: -0.0004056301127235563\n",
      "Training loss: -0.0004056001357649182\n",
      "Training loss: -0.00040557016191295115\n",
      "Training loss: -0.0004055401911672422\n",
      "Training loss: -0.00040551022352737867\n",
      "Training loss: -0.00040548025899294916\n",
      "Training loss: -0.00040545029756354213\n",
      "Training loss: -0.0004054203392387428\n",
      "Training loss: -0.00040539038401813955\n",
      "Training loss: -0.00040536043190132244\n",
      "Training loss: -0.00040533048288787565\n",
      "Training loss: -0.0004053005369773906\n",
      "Training loss: -0.00040527059416945295\n",
      "Training loss: -0.00040524065446365256\n",
      "Training loss: -0.0004052107178595767\n",
      "Training loss: -0.0004051807843568138\n",
      "Training loss: -0.0004051508539549523\n",
      "Training loss: -0.00040512092665357974\n",
      "Training loss: -0.00040509100245228447\n",
      "Training loss: -0.00040506108135065615\n",
      "Training loss: -0.00040503116334828323\n",
      "Training loss: -0.00040500124844475245\n",
      "Training loss: -0.0004049713366396557\n",
      "Training loss: -0.0004049414279325789\n",
      "Training loss: -0.00040491152232311145\n",
      "Training loss: -0.00040488161981084436\n",
      "Training loss: -0.0004048517203953637\n",
      "Training loss: -0.0004048218240762602\n",
      "Training loss: -0.0004047919308531215\n",
      "Training loss: -0.0004047620407255384\n",
      "Training loss: -0.00040473215369309974\n",
      "Training loss: -0.0004047022697553954\n",
      "Training loss: -0.00040467238891201166\n",
      "Training loss: -0.00040464251116254115\n",
      "Training loss: -0.0004046126365065727\n",
      "Training loss: -0.00040458276494369526\n",
      "Training loss: -0.00040455289647349903\n",
      "Training loss: -0.00040452303109557187\n",
      "Training loss: -0.0004044931688095066\n",
      "Training loss: -0.0004044633096148924\n",
      "Training loss: -0.0004044334535113169\n",
      "Training loss: -0.00040440360049837093\n",
      "Training loss: -0.0004043737505756463\n",
      "Training loss: -0.0004043439037427301\n",
      "Training loss: -0.00040431405999921373\n",
      "Training loss: -0.0004042842193446881\n",
      "Training loss: -0.0004042543817787441\n",
      "Training loss: -0.0004042245473009701\n",
      "Training loss: -0.0004041947159109574\n",
      "Training loss: -0.00040416488760829734\n",
      "Training loss: -0.00040413506239257843\n",
      "Training loss: -0.0004041052402633929\n",
      "Training loss: -0.0004040754212203314\n",
      "Training loss: -0.0004040456052629843\n",
      "Training loss: -0.00040401579239094076\n",
      "Training loss: -0.00040398598260379546\n",
      "Training loss: -0.0004039561759011348\n",
      "Training loss: -0.00040392637228255416\n",
      "Training loss: -0.0004038965717476422\n",
      "Training loss: -0.00040386677429598915\n",
      "Training loss: -0.000403836979927189\n",
      "Training loss: -0.00040380718864083104\n",
      "Training loss: -0.0004037774004365069\n",
      "Training loss: -0.0004037476153138068\n",
      "Training loss: -0.00040371783327232484\n",
      "Training loss: -0.0004036880543116507\n",
      "Training loss: -0.0004036582784313761\n",
      "Training loss: -0.0004036285056310927\n",
      "Training loss: -0.0004035987359103939\n",
      "Training loss: -0.0004035689692688691\n",
      "Training loss: -0.0004035392057061118\n",
      "Training loss: -0.000403509445221714\n",
      "Training loss: -0.00040347968781526545\n",
      "Training loss: -0.00040344993348635934\n",
      "Training loss: -0.0004034201822345893\n",
      "Training loss: -0.0004033904340595454\n",
      "Training loss: -0.0004033606889608212\n",
      "Training loss: -0.0004033309469380088\n",
      "Training loss: -0.00040330120799069976\n",
      "Training loss: -0.00040327147211848663\n",
      "Training loss: -0.000403241739320964\n",
      "Training loss: -0.0004032120095977227\n",
      "Training loss: -0.00040318228294835374\n",
      "Training loss: -0.00040315255937245243\n",
      "Training loss: -0.0004031228388696104\n",
      "Training loss: -0.00040309312143942073\n",
      "Training loss: -0.00040306340708147834\n",
      "Training loss: -0.00040303369579537245\n",
      "Training loss: -0.0004030039875806982\n",
      "Training loss: -0.00040297428243704755\n",
      "Training loss: -0.00040294458036401544\n",
      "Training loss: -0.00040291488136119246\n",
      "Training loss: -0.00040288518542817527\n",
      "Training loss: -0.0004028554925645543\n",
      "Training loss: -0.0004028258027699255\n",
      "Training loss: -0.0004027961160438805\n",
      "Training loss: -0.0004027664323860113\n",
      "Training loss: -0.00040273675179591605\n",
      "Training loss: -0.0004027070742731852\n",
      "Training loss: -0.00040267739981741176\n",
      "Training loss: -0.00040264772842819245\n",
      "Training loss: -0.00040261806010511916\n",
      "Training loss: -0.00040258839484778717\n",
      "Training loss: -0.0004025587326557878\n",
      "Training loss: -0.0004025290735287176\n",
      "Training loss: -0.0004024994174661697\n",
      "Training loss: -0.0004024697644677404\n",
      "Training loss: -0.0004024401145330217\n",
      "Training loss: -0.00040241046766160813\n",
      "Training loss: -0.00040238082385309445\n",
      "Training loss: -0.00040235118310707427\n",
      "Training loss: -0.00040232154542314407\n",
      "Training loss: -0.00040229191080089574\n",
      "Training loss: -0.00040226227923992694\n",
      "Training loss: -0.00040223265073983006\n",
      "Training loss: -0.00040220302530019956\n",
      "Training loss: -0.00040217340292063325\n",
      "Training loss: -0.0004021437836007233\n",
      "Training loss: -0.00040211416734006603\n",
      "Training loss: -0.0004020845541382555\n",
      "Training loss: -0.0004020549439948881\n",
      "Training loss: -0.0004020253369095583\n",
      "Training loss: -0.00040199573288186104\n",
      "Training loss: -0.0004019661319113914\n",
      "Training loss: -0.0004019365339977462\n",
      "Training loss: -0.0004019069391405185\n",
      "Training loss: -0.0004018773473393067\n",
      "Training loss: -0.000401847758593705\n",
      "Training loss: -0.00040181817290330704\n",
      "Training loss: -0.000401788590267713\n",
      "Training loss: -0.0004017590106865132\n",
      "Training loss: -0.000401729434159308\n",
      "Training loss: -0.0004016998606856912\n",
      "Training loss: -0.0004016702902652585\n",
      "Training loss: -0.0004016407228976076\n",
      "Training loss: -0.000401611158582333\n",
      "Training loss: -0.00040158159731903004\n",
      "Training loss: -0.00040155203910729716\n",
      "Training loss: -0.00040152248394672847\n",
      "Training loss: -0.00040149293183692336\n",
      "Training loss: -0.0004014633827774752\n",
      "Training loss: -0.0004014338367679824\n",
      "Training loss: -0.0004014042938080395\n",
      "Training loss: -0.00040137475389724516\n",
      "Training loss: -0.00040134521703519494\n",
      "Training loss: -0.0004013156832214863\n",
      "Training loss: -0.00040128615245571525\n",
      "Training loss: -0.0004012566247374782\n",
      "Training loss: -0.00040122710006637347\n",
      "Training loss: -0.0004011975784419974\n",
      "Training loss: -0.00040116805986394657\n",
      "Training loss: -0.00040113854433181855\n",
      "Training loss: -0.0004011090318452102\n",
      "Training loss: -0.00040107952240372015\n",
      "Training loss: -0.00040105001600694313\n",
      "Training loss: -0.00040102051265447966\n",
      "Training loss: -0.0004009910123459237\n",
      "Training loss: -0.0004009615150808746\n",
      "Training loss: -0.0004009320208589305\n",
      "Training loss: -0.0004009025296796888\n",
      "Training loss: -0.00040087304154274645\n",
      "Training loss: -0.00040084355644770205\n",
      "Training loss: -0.0004008140743941521\n",
      "Training loss: -0.00040078459538169653\n",
      "Training loss: -0.0004007551194099306\n",
      "Training loss: -0.00040072564647845394\n",
      "Training loss: -0.0004006961765868639\n",
      "Training loss: -0.00040066670973476005\n",
      "Training loss: -0.00040063724592173845\n",
      "Training loss: -0.00040060778514739993\n",
      "Training loss: -0.0004005783274113422\n",
      "Training loss: -0.00040054887271316093\n",
      "Training loss: -0.00040051942105245777\n",
      "Training loss: -0.00040048997242882856\n",
      "Training loss: -0.0004004605268418752\n",
      "Training loss: -0.0004004310842911933\n",
      "Training loss: -0.0004004016447763845\n",
      "Training loss: -0.0004003722082970445\n",
      "Training loss: -0.0004003427748527752\n",
      "Training loss: -0.00040031334444317224\n",
      "Training loss: -0.00040028391706783663\n",
      "Training loss: -0.00040025449272636807\n",
      "Training loss: -0.0004002250714183644\n",
      "Training loss: -0.0004001956531434243\n",
      "Training loss: -0.00040016623790114776\n",
      "Training loss: -0.0004001368256911344\n",
      "Training loss: -0.00040010741651298363\n",
      "Training loss: -0.0004000780103662938\n",
      "Training loss: -0.0004000486072506641\n",
      "Training loss: -0.00040001920716569583\n",
      "Training loss: -0.00039998981011098693\n",
      "Training loss: -0.0003999604160861386\n",
      "Training loss: -0.00039993102509075154\n",
      "Training loss: -0.00039990163712442205\n",
      "Training loss: -0.00039987225218675364\n",
      "Training loss: -0.0003998428702773426\n",
      "Training loss: -0.0003998134913957909\n",
      "Training loss: -0.0003997841155416993\n",
      "Training loss: -0.00039975474271466705\n",
      "Training loss: -0.00039972537291429474\n",
      "Training loss: -0.0003996960061401826\n",
      "Training loss: -0.00039966664239192917\n",
      "Training loss: -0.0003996372816691375\n",
      "Training loss: -0.0003996079239714065\n",
      "Training loss: -0.0003995785692983365\n",
      "Training loss: -0.00039954921764952944\n",
      "Training loss: -0.0003995198690245843\n",
      "Training loss: -0.000399490523423104\n",
      "Training loss: -0.000399461180844688\n",
      "Training loss: -0.000399431841288936\n",
      "Training loss: -0.00039940250475545074\n",
      "Training loss: -0.0003993731712438316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: -0.0003993438407536819\n",
      "Training loss: -0.00039931451328460043\n",
      "Training loss: -0.00039928518883618896\n",
      "Training loss: -0.0003992558674080486\n",
      "Training loss: -0.00039922654899978127\n",
      "Training loss: -0.00039919723361098815\n",
      "Training loss: -0.00039916792124127036\n",
      "Training loss: -0.0003991386118902291\n",
      "Training loss: -0.00039910930555746673\n",
      "Training loss: -0.0003990800022425843\n",
      "Training loss: -0.00039905070194518337\n",
      "Training loss: -0.0003990214046648658\n",
      "Training loss: -0.0003989921104012345\n",
      "Training loss: -0.0003989628191538887\n",
      "Training loss: -0.0003989335309224327\n",
      "Training loss: -0.0003989042457064678\n",
      "Training loss: -0.0003988749635055955\n",
      "Training loss: -0.0003988456843194191\n",
      "Training loss: -0.0003988164081475389\n",
      "Training loss: -0.0003987871349895579\n",
      "Training loss: -0.00039875786484507903\n",
      "Training loss: -0.00039872859771370437\n",
      "Training loss: -0.0003986993335950366\n",
      "Training loss: -0.0003986700724886771\n",
      "Training loss: -0.0003986408143942299\n",
      "Training loss: -0.00039861155931129606\n",
      "Training loss: -0.00039858230723947906\n",
      "Training loss: -0.00039855305817838307\n",
      "Training loss: -0.00039852381212760835\n",
      "Training loss: -0.0003984945690867593\n",
      "Training loss: -0.0003984653290554374\n",
      "Training loss: -0.0003984360920332471\n",
      "Training loss: -0.0003984068580197924\n",
      "Training loss: -0.00039837762701467276\n",
      "Training loss: -0.0003983483990174954\n",
      "Training loss: -0.00039831917402786076\n",
      "Training loss: -0.0003982899520453744\n",
      "Training loss: -0.00039826073306963765\n",
      "Training loss: -0.00039823151710025593\n",
      "Training loss: -0.00039820230413683053\n",
      "Training loss: -0.0003981730941789666\n",
      "Training loss: -0.00039814388722626636\n",
      "Training loss: -0.0003981146832783347\n",
      "Training loss: -0.00039808548233477646\n",
      "Training loss: -0.0003980562843951918\n",
      "Training loss: -0.00039802708945918877\n",
      "Training loss: -0.00039799789752636815\n",
      "Training loss: -0.0003979687085963355\n",
      "Training loss: -0.0003979395226686943\n",
      "Training loss: -0.00039791033974304876\n",
      "Training loss: -0.00039788115981900384\n",
      "Training loss: -0.0003978519828961644\n",
      "Training loss: -0.000397822808974132\n",
      "Training loss: -0.00039779363805251286\n",
      "Training loss: -0.00039776447013091103\n",
      "Training loss: -0.00039773530520893205\n",
      "Training loss: -0.0003977061432861784\n",
      "Training loss: -0.00039767698436225655\n",
      "Training loss: -0.00039764782843677106\n",
      "Training loss: -0.00039761867550932515\n",
      "Training loss: -0.0003975895255795249\n",
      "Training loss: -0.00039756037864697546\n",
      "Training loss: -0.0003975312347112805\n",
      "Training loss: -0.00039750209377204687\n",
      "Training loss: -0.0003974729558288788\n",
      "Training loss: -0.00039744382088138005\n",
      "Training loss: -0.00039741468892915874\n",
      "Training loss: -0.0003973855599718176\n",
      "Training loss: -0.0003973564340089625\n",
      "Training loss: -0.0003973273110401989\n",
      "Training loss: -0.00039729819106513374\n",
      "Training loss: -0.0003972690740833699\n",
      "Training loss: -0.00039723996009451384\n",
      "Training loss: -0.00039721084909817296\n",
      "Training loss: -0.000397181741093951\n",
      "Training loss: -0.0003971526360814551\n",
      "Training loss: -0.00039712353406029\n",
      "Training loss: -0.0003970944350300614\n",
      "Training loss: -0.0003970653389903769\n",
      "Training loss: -0.00039703624594084123\n",
      "Training loss: -0.00039700715588106056\n",
      "Training loss: -0.0003969780688106409\n",
      "Training loss: -0.0003969489847291901\n",
      "Training loss: -0.00039691990363631185\n",
      "Training loss: -0.0003968908255316147\n",
      "Training loss: -0.0003968617504147037\n",
      "Training loss: -0.000396832678285186\n",
      "Training loss: -0.00039680360914266766\n",
      "Training loss: -0.00039677454298675606\n",
      "Training loss: -0.00039674547981705615\n",
      "Training loss: -0.0003967164196331755\n",
      "Training loss: -0.00039668736243472194\n",
      "Training loss: -0.00039665830822129986\n",
      "Training loss: -0.0003966292569925197\n",
      "Training loss: -0.00039660020874798433\n",
      "Training loss: -0.0003965711634873047\n",
      "Training loss: -0.00039654212121008553\n",
      "Training loss: -0.00039651308191593565\n",
      "Training loss: -0.0003964840456044602\n",
      "Training loss: -0.00039645501227526797\n",
      "Training loss: -0.00039642598192796656\n",
      "Training loss: -0.00039639695456216047\n",
      "Training loss: -0.00039636793017746083\n",
      "Training loss: -0.00039633890877347416\n",
      "Training loss: -0.00039630989034980524\n",
      "Training loss: -0.0003962808749060661\n",
      "Training loss: -0.0003962518624418609\n",
      "Training loss: -0.0003962228529567995\n",
      "Training loss: -0.0003961938464504891\n",
      "Training loss: -0.00039616484292253706\n",
      "Training loss: -0.0003961358423725523\n",
      "Training loss: -0.00039610684480014343\n",
      "Training loss: -0.00039607785020491547\n",
      "Training loss: -0.0003960488585864808\n",
      "Training loss: -0.00039601986994444445\n",
      "Training loss: -0.0003959908842784149\n",
      "Training loss: -0.0003959619015880016\n",
      "Training loss: -0.00039593292187281375\n",
      "Training loss: -0.0003959039451324569\n",
      "Training loss: -0.00039587497136654297\n",
      "Training loss: -0.00039584600057467783\n",
      "Training loss: -0.00039581703275647193\n",
      "Training loss: -0.0003957880679115322\n",
      "Training loss: -0.0003957591060394698\n",
      "Training loss: -0.0003957301471398916\n",
      "Training loss: -0.00039570119121240755\n",
      "Training loss: -0.00039567223825662576\n",
      "Training loss: -0.0003956432882721562\n",
      "Training loss: -0.0003956143412586078\n",
      "Training loss: -0.0003955853972155885\n",
      "Training loss: -0.00039555645614270746\n",
      "Training loss: -0.000395527518039577\n",
      "Training loss: -0.00039549858290580217\n",
      "Training loss: -0.0003954696507409957\n",
      "Training loss: -0.00039544072154476637\n",
      "Training loss: -0.00039541179531672277\n",
      "Training loss: -0.00039538287205647565\n",
      "Training loss: -0.00039535395176363257\n",
      "Training loss: -0.0003953250344378062\n",
      "Training loss: -0.0003952961200786034\n",
      "Training loss: -0.000395267208685636\n",
      "Training loss: -0.00039523830025851284\n",
      "Training loss: -0.00039520939479684473\n",
      "Training loss: -0.0003951804923002411\n",
      "Training loss: -0.00039515159276831067\n",
      "Training loss: -0.0003951226962006665\n",
      "Training loss: -0.00039509380259691705\n",
      "Training loss: -0.00039506491195667373\n",
      "Training loss: -0.00039503602427954574\n",
      "Training loss: -0.00039500713956514195\n",
      "Training loss: -0.0003949782578130752\n",
      "Training loss: -0.00039494937902295665\n",
      "Training loss: -0.00039492050319439516\n",
      "Training loss: -0.00039489163032700107\n",
      "Training loss: -0.0003948627604203861\n",
      "Training loss: -0.0003948338934741619\n",
      "Training loss: -0.00039480502948793664\n",
      "Training loss: -0.0003947761684613242\n",
      "Training loss: -0.0003947473103939336\n",
      "Training loss: -0.0003947184552853748\n",
      "Training loss: -0.0003946896031352617\n",
      "Training loss: -0.0003946607539432031\n",
      "Training loss: -0.00039463190770881225\n",
      "Training loss: -0.0003946030644316991\n",
      "Training loss: -0.0003945742241114744\n",
      "Training loss: -0.0003945453867477508\n",
      "Training loss: -0.00039451655234014007\n",
      "Training loss: -0.00039448772088825285\n",
      "Training loss: -0.00039445889239169974\n",
      "Training loss: -0.00039443006685009385\n",
      "Training loss: -0.0003944012442630473\n",
      "Training loss: -0.00039437242463016906\n",
      "Training loss: -0.0003943436079510731\n",
      "Training loss: -0.00039431479422537226\n",
      "Training loss: -0.00039428598345267777\n",
      "Training loss: -0.0003942571756326003\n",
      "Training loss: -0.000394228370764752\n",
      "Training loss: -0.00039419956884874694\n",
      "Training loss: -0.00039417076988419465\n",
      "Training loss: -0.00039414197387070975\n",
      "Training loss: -0.0003941131808079039\n",
      "Training loss: -0.0003940843906953889\n",
      "Training loss: -0.0003940556035327764\n",
      "Training loss: -0.00039402681931968107\n",
      "Training loss: -0.00039399803805571467\n",
      "Training loss: -0.00039396925974048783\n",
      "Training loss: -0.0003939404843736155\n",
      "Training loss: -0.0003939117119547105\n",
      "Training loss: -0.00039388294248338335\n",
      "Training loss: -0.00039385417595924936\n",
      "Training loss: -0.0003938254123819212\n",
      "Training loss: -0.00039379665175101093\n",
      "Training loss: -0.00039376789406613157\n",
      "Training loss: -0.00039373913932689593\n",
      "Training loss: -0.00039371038753291903\n",
      "Training loss: -0.000393681638683812\n",
      "Training loss: -0.0003936528927791899\n",
      "Training loss: -0.00039362414981866455\n",
      "Training loss: -0.00039359540980184947\n",
      "Training loss: -0.0003935666727283579\n",
      "Training loss: -0.00039353793859780555\n",
      "Training loss: -0.0003935092074098053\n",
      "Training loss: -0.00039348047916396776\n",
      "Training loss: -0.0003934517538599115\n",
      "Training loss: -0.00039342303149724666\n",
      "Training loss: -0.0003933943120755877\n",
      "Training loss: -0.00039336559559455015\n",
      "Training loss: -0.00039333688205374774\n",
      "Training loss: -0.00039330817145279135\n",
      "Training loss: -0.0003932794637912991\n",
      "Training loss: -0.0003932507590688835\n",
      "Training loss: -0.00039322205728515745\n",
      "Training loss: -0.00039319335843973705\n",
      "Training loss: -0.00039316466253223555\n",
      "Training loss: -0.00039313596956226725\n",
      "Training loss: -0.0003931072795294484\n",
      "Training loss: -0.00039307859243339086\n",
      "Training loss: -0.0003930499082737112\n",
      "Training loss: -0.000393021227050023\n",
      "Training loss: -0.00039299254876194186\n",
      "Training loss: -0.0003929638734090819\n",
      "Training loss: -0.00039293520099105796\n",
      "Training loss: -0.00039290653150748646\n",
      "Training loss: -0.0003928778649579801\n",
      "Training loss: -0.0003928492013421545\n",
      "Training loss: -0.0003928205406596257\n",
      "Training loss: -0.000392791882910007\n",
      "Training loss: -0.00039276322809291594\n",
      "Training loss: -0.000392734576207966\n",
      "Training loss: -0.0003927059272547742\n",
      "Training loss: -0.00039267728123295426\n",
      "Training loss: -0.00039264863814212264\n",
      "Training loss: -0.0003926199979818939\n",
      "Training loss: -0.0003925913607518836\n",
      "Training loss: -0.00039256272645170814\n",
      "Training loss: -0.0003925340950809828\n",
      "Training loss: -0.000392505466639323\n",
      "Training loss: -0.0003924768411263447\n",
      "Training loss: -0.0003924482185416653\n",
      "Training loss: -0.00039241959888489824\n",
      "Training loss: -0.00039239098215566127\n",
      "Training loss: -0.00039236236835356943\n",
      "Training loss: -0.0003923337574782401\n",
      "Training loss: -0.00039230514952928703\n",
      "Training loss: -0.0003922765445063299\n",
      "Training loss: -0.0003922479424089813\n",
      "Training loss: -0.00039221934323686034\n",
      "Training loss: -0.0003921907469895821\n",
      "Training loss: -0.00039216215366676447\n",
      "Training loss: -0.00039213356326802204\n",
      "Training loss: -0.00039210497579297214\n",
      "Training loss: -0.00039207639124123303\n",
      "Training loss: -0.00039204780961241863\n",
      "Training loss: -0.0003920192309061472\n",
      "Training loss: -0.00039199065512203506\n",
      "Training loss: -0.0003919620822596993\n",
      "Training loss: -0.00039193351231875796\n",
      "Training loss: -0.00039190494529882554\n",
      "Training loss: -0.0003918763811995233\n",
      "Training loss: -0.0003918478200204642\n",
      "Training loss: -0.0003918192617612672\n",
      "Training loss: -0.0003917907064215497\n",
      "Training loss: -0.00039176215400092836\n",
      "Training loss: -0.00039173360449902225\n",
      "Training loss: -0.00039170505791544664\n",
      "Training loss: -0.0003916765142498197\n",
      "Training loss: -0.0003916479735017589\n",
      "Training loss: -0.0003916194356708829\n",
      "Training loss: -0.00039159090075680815\n",
      "Training loss: -0.0003915623687591526\n",
      "Training loss: -0.0003915338396775348\n",
      "Training loss: -0.00039150531351157147\n",
      "Training loss: -0.00039147679026088226\n",
      "Training loss: -0.0003914482699250827\n",
      "Training loss: -0.0003914197525037935\n",
      "Training loss: -0.0003913912379966325\n",
      "Training loss: -0.0003913627264032154\n",
      "Training loss: -0.00039133421772316146\n",
      "Training loss: -0.0003913057119560911\n",
      "Training loss: -0.00039127720910161893\n",
      "Training loss: -0.00039124870915936726\n",
      "Training loss: -0.0003912202121289523\n",
      "Training loss: -0.00039119171800999276\n",
      "Training loss: -0.00039116322680210784\n",
      "Training loss: -0.00039113473850491603\n",
      "Training loss: -0.0003911062531180361\n",
      "Training loss: -0.0003910777706410872\n",
      "Training loss: -0.00039104929107368596\n",
      "Training loss: -0.00039102081441545457\n",
      "Training loss: -0.0003909923406660092\n",
      "Training loss: -0.00039096386982497103\n",
      "Training loss: -0.00039093540189195675\n",
      "Training loss: -0.0003909069368665881\n",
      "Training loss: -0.00039087847474848325\n",
      "Training loss: -0.0003908500155372603\n",
      "Training loss: -0.0003908215592325395\n",
      "Training loss: -0.00039079310583394074\n",
      "Training loss: -0.00039076465534108325\n",
      "Training loss: -0.00039073620775358575\n",
      "Training loss: -0.0003907077630710672\n",
      "Training loss: -0.0003906793212931488\n",
      "Training loss: -0.00039065088241945005\n",
      "Training loss: -0.0003906224464495908\n",
      "Training loss: -0.00039059401338318987\n",
      "Training loss: -0.0003905655832198677\n",
      "Training loss: -0.00039053715595924453\n",
      "Training loss: -0.0003905087316009416\n",
      "Training loss: -0.0003904803101445762\n",
      "Training loss: -0.00039045189158976826\n",
      "Training loss: -0.00039042347593614096\n",
      "Training loss: -0.00039039506318331105\n",
      "Training loss: -0.00039036665333090187\n",
      "Training loss: -0.00039033824637853194\n",
      "Training loss: -0.00039030984232582403\n",
      "Training loss: -0.0003902814411723954\n",
      "Training loss: -0.00039025304291786774\n",
      "Training loss: -0.0003902246475618617\n",
      "Training loss: -0.0003901962551039987\n",
      "Training loss: -0.000390167865543899\n",
      "Training loss: -0.0003901394788811829\n",
      "Training loss: -0.00039011109511547204\n",
      "Training loss: -0.000390082714246386\n",
      "Training loss: -0.0003900543362735468\n",
      "Training loss: -0.0003900259611965752\n",
      "Training loss: -0.00038999758901509153\n",
      "Training loss: -0.00038996921972871975\n",
      "Training loss: -0.00038994085333707784\n",
      "Training loss: -0.00038991248983978816\n",
      "Training loss: -0.000389884129236472\n",
      "Training loss: -0.00038985577152675095\n",
      "Training loss: -0.0003898274167102455\n",
      "Training loss: -0.0003897990647865788\n",
      "Training loss: -0.0003897707157553713\n",
      "Training loss: -0.0003897423696162441\n",
      "Training loss: -0.0003897140263688192\n",
      "Training loss: -0.00038968568601272\n",
      "Training loss: -0.00038965734854756463\n",
      "Training loss: -0.00038962901397297876\n",
      "Training loss: -0.00038960068228858347\n",
      "Training loss: -0.00038957235349399935\n",
      "Training loss: -0.0003895440275888483\n",
      "Training loss: -0.0003895157045727538\n",
      "Training loss: -0.00038948738444533754\n",
      "Training loss: -0.0003894590672062215\n",
      "Training loss: -0.00038943075285502763\n",
      "Training loss: -0.0003894024413913799\n",
      "Training loss: -0.00038937413281489906\n",
      "Training loss: -0.00038934582712520696\n",
      "Training loss: -0.00038931752432192824\n",
      "Training loss: -0.00038928922440468225\n",
      "Training loss: -0.0003892609273730949\n",
      "Training loss: -0.0003892326332267882\n",
      "Training loss: -0.000389204341965383\n",
      "Training loss: -0.00038917605358850416\n",
      "Training loss: -0.0003891477680957741\n",
      "Training loss: -0.00038911948548681454\n",
      "Training loss: -0.0003890912057612496\n",
      "Training loss: -0.00038906292891870267\n",
      "Training loss: -0.00038903465495879517\n",
      "Training loss: -0.00038900638388115186\n",
      "Training loss: -0.0003889781156853955\n",
      "Training loss: -0.00038894985037114956\n",
      "Training loss: -0.00038892158793803704\n",
      "Training loss: -0.00038889332838568054\n",
      "Training loss: -0.00038886507171370514\n",
      "Training loss: -0.00038883681792173413\n",
      "Training loss: -0.0003888085670093895\n",
      "Training loss: -0.0003887803189762975\n",
      "Training loss: -0.00038875207382207787\n",
      "Training loss: -0.0003887238315463589\n",
      "Training loss: -0.0003886955921487601\n",
      "Training loss: -0.000388667355628909\n",
      "Training loss: -0.0003886391219864278\n",
      "Training loss: -0.0003886108912209411\n",
      "Training loss: -0.00038858266333207167\n",
      "Training loss: -0.0003885544383194445\n",
      "Training loss: -0.0003885262161826846\n",
      "Training loss: -0.00038849799692141626\n",
      "Training loss: -0.00038846978053526127\n",
      "Training loss: -0.0003884415670238467\n",
      "Training loss: -0.000388413356386795\n",
      "Training loss: -0.00038838514862373093\n",
      "Training loss: -0.0003883569437342804\n",
      "Training loss: -0.00038832874171806746\n",
      "Training loss: -0.00038830054257471547\n",
      "Training loss: -0.0003882723463038509\n",
      "Training loss: -0.0003882441529050984\n",
      "Training loss: -0.000388215962378081\n",
      "Training loss: -0.0003881877747224262\n",
      "Training loss: -0.00038815958993775664\n",
      "Training loss: -0.00038813140802369757\n",
      "Training loss: -0.0003881032289798755\n",
      "Training loss: -0.0003880750528059158\n",
      "Training loss: -0.0003880468795014414\n",
      "Training loss: -0.00038801870906607887\n",
      "Training loss: -0.0003879905414994527\n",
      "Training loss: -0.0003879623768011893\n",
      "Training loss: -0.0003879342149709143\n",
      "Training loss: -0.0003879060560082522\n",
      "Training loss: -0.0003878778999128275\n",
      "Training loss: -0.0003878497466842684\n",
      "Training loss: -0.00038782159632220044\n",
      "Training loss: -0.0003877934488262471\n",
      "Training loss: -0.00038776530419603537\n",
      "Training loss: -0.0003877371624311913\n",
      "Training loss: -0.0003877090235313394\n",
      "Training loss: -0.0003876808874961072\n",
      "Training loss: -0.0003876527543251207\n",
      "Training loss: -0.00038762462401800577\n",
      "Training loss: -0.00038759649657438733\n",
      "Training loss: -0.0003875683719938932\n",
      "Training loss: -0.000387540250276148\n",
      "Training loss: -0.0003875121314207805\n",
      "Training loss: -0.00038748401542741483\n",
      "Training loss: -0.0003874559022956772\n",
      "Training loss: -0.00038742779202519643\n",
      "Training loss: -0.0003873996846155957\n",
      "Training loss: -0.00038737158006650347\n",
      "Training loss: -0.0003873434783775479\n",
      "Training loss: -0.0003873153795483531\n",
      "Training loss: -0.00038728728357854806\n",
      "Training loss: -0.000387259190467757\n",
      "Training loss: -0.0003872311002156094\n",
      "Training loss: -0.00038720301282173215\n",
      "Training loss: -0.00038717492828575035\n",
      "Training loss: -0.00038714684660729165\n",
      "Training loss: -0.0003871187677859836\n",
      "Training loss: -0.0003870906918214536\n",
      "Training loss: -0.0003870626187133283\n",
      "Training loss: -0.00038703454846123636\n",
      "Training loss: -0.0003870064810648038\n",
      "Training loss: -0.00038697841652365764\n",
      "Training loss: -0.0003869503548374263\n",
      "Training loss: -0.0003869222960057372\n",
      "Training loss: -0.0003868942400282177\n",
      "Training loss: -0.00038686618690449517\n",
      "Training loss: -0.000386838136634198\n",
      "Training loss: -0.00038681008921695426\n",
      "Training loss: -0.0003867820446523909\n",
      "Training loss: -0.0003867540029401359\n",
      "Training loss: -0.00038672596407981786\n",
      "Training loss: -0.00038669792807106436\n",
      "Training loss: -0.00038666989491350384\n",
      "Training loss: -0.00038664186460676315\n",
      "Training loss: -0.0003866138371504719\n",
      "Training loss: -0.0003865858125442577\n",
      "Training loss: -0.000386557790787749\n",
      "Training loss: -0.00038652977188057415\n",
      "Training loss: -0.00038650175582236046\n",
      "Training loss: -0.0003864737426127394\n",
      "Training loss: -0.00038644573225133717\n",
      "Training loss: -0.0003864177247377824\n",
      "Training loss: -0.000386389720071705\n",
      "Training loss: -0.000386361718252732\n",
      "Training loss: -0.00038633371928049393\n",
      "Training loss: -0.000386305723154618\n",
      "Training loss: -0.00038627772987473376\n",
      "Training loss: -0.00038624973944047133\n",
      "Training loss: -0.00038622175185145714\n",
      "Training loss: -0.00038619376710732304\n",
      "Training loss: -0.0003861657852076959\n",
      "Training loss: -0.00038613780615220553\n",
      "Training loss: -0.000386109829940482\n",
      "Training loss: -0.0003860818565721552\n",
      "Training loss: -0.0003860538860468541\n",
      "Training loss: -0.00038602591836420593\n",
      "Training loss: -0.00038599795352384225\n",
      "Training loss: -0.0003859699915253919\n",
      "Training loss: -0.00038594203236848394\n",
      "Training loss: -0.00038591407605274874\n",
      "Training loss: -0.0003858861225778162\n",
      "Training loss: -0.0003858581719433171\n",
      "Training loss: -0.00038583022414887875\n",
      "Training loss: -0.0003858022791941322\n",
      "Training loss: -0.0003857743370787074\n",
      "Training loss: -0.0003857463978022342\n",
      "Training loss: -0.00038571846136434404\n",
      "Training loss: -0.0003856905277646649\n",
      "Training loss: -0.00038566259700282824\n",
      "Training loss: -0.00038563466907846406\n",
      "Training loss: -0.0003856067439912018\n",
      "Training loss: -0.000385578821740674\n",
      "Training loss: -0.0003855509023265086\n",
      "Training loss: -0.00038552298574833795\n",
      "Training loss: -0.0003854950720057922\n",
      "Training loss: -0.00038546716109850033\n",
      "Training loss: -0.0003854392530260951\n",
      "Training loss: -0.000385411347788206\n",
      "Training loss: -0.00038538344538446455\n",
      "Training loss: -0.0003853555458145007\n",
      "Training loss: -0.0003853276490779453\n",
      "Training loss: -0.0003852997551744301\n",
      "Training loss: -0.0003852718641035859\n",
      "Training loss: -0.0003852439758650437\n",
      "Training loss: -0.00038521609045843335\n",
      "Training loss: -0.00038518820788338744\n",
      "Training loss: -0.00038516032813953687\n",
      "Training loss: -0.00038513245122651356\n",
      "Training loss: -0.0003851045771439472\n",
      "Training loss: -0.000385076705891471\n",
      "Training loss: -0.000385048837468715\n",
      "Training loss: -0.00038502097187531197\n",
      "Training loss: -0.0003849931091108936\n",
      "Training loss: -0.0003849652491750895\n",
      "Training loss: -0.00038493739206753357\n",
      "Training loss: -0.0003849095377878558\n",
      "Training loss: -0.00038488168633568913\n",
      "Training loss: -0.0003848538377106655\n",
      "Training loss: -0.0003848259919124151\n",
      "Training loss: -0.0003847981489405731\n",
      "Training loss: -0.0003847703087947681\n",
      "Training loss: -0.00038474247147463503\n",
      "Training loss: -0.0003847146369798048\n",
      "Training loss: -0.00038468680530990976\n",
      "Training loss: -0.00038465897646458103\n",
      "Training loss: -0.00038463115044345237\n",
      "Training loss: -0.0003846033272461559\n",
      "Training loss: -0.0003845755068723233\n",
      "Training loss: -0.00038454768932158793\n",
      "Training loss: -0.0003845198745935827\n",
      "Training loss: -0.00038449206268793905\n",
      "Training loss: -0.00038446425360429083\n",
      "Training loss: -0.0003844364473422705\n",
      "Training loss: -0.0003844086439015102\n",
      "Training loss: -0.0003843808432816421\n",
      "Training loss: -0.00038435304548230085\n",
      "Training loss: -0.0003843252505031191\n",
      "Training loss: -0.0003842974583437287\n",
      "Training loss: -0.00038426966900376397\n",
      "Training loss: -0.00038424188248285774\n",
      "Training loss: -0.0003842140987806432\n",
      "Training loss: -0.00038418631789675266\n",
      "Training loss: -0.0003841585398308199\n",
      "Training loss: -0.00038413076458247865\n",
      "Training loss: -0.0003841029921513635\n",
      "Training loss: -0.000384075222537106\n",
      "Training loss: -0.00038404745573934133\n",
      "Training loss: -0.0003840196917577003\n",
      "Training loss: -0.0003839919305918204\n",
      "Training loss: -0.000383964172241332\n",
      "Training loss: -0.0003839364167058704\n",
      "Training loss: -0.0003839086639850693\n",
      "Training loss: -0.00038388091407856324\n",
      "Training loss: -0.00038385316698598523\n",
      "Training loss: -0.00038382542270696846\n",
      "Training loss: -0.00038379768124114944\n",
      "Training loss: -0.0003837699425881609\n",
      "Training loss: -0.0003837422067476366\n",
      "Training loss: -0.00038371447371921235\n",
      "Training loss: -0.00038368674350251986\n",
      "Training loss: -0.0003836590160971952\n",
      "Training loss: -0.0003836312915028723\n",
      "Training loss: -0.00038360356971918626\n",
      "Training loss: -0.00038357585074577145\n",
      "Training loss: -0.00038354813458226097\n",
      "Training loss: -0.0003835204212282916\n",
      "Training loss: -0.0003834927106834975\n",
      "Training loss: -0.0003834650029475118\n",
      "Training loss: -0.00038343729801997164\n",
      "Training loss: -0.00038340959590051115\n",
      "Training loss: -0.0003833818965887636\n",
      "Training loss: -0.0003833542000843652\n",
      "Training loss: -0.0003833265063869516\n",
      "Training loss: -0.0003832988154961574\n",
      "Training loss: -0.0003832711274116173\n",
      "Training loss: -0.00038324344213296833\n",
      "Training loss: -0.0003832157596598432\n",
      "Training loss: -0.00038318807999187897\n",
      "Training loss: -0.0003831604031287094\n",
      "Training loss: -0.0003831327290699718\n",
      "Training loss: -0.0003831050578153001\n",
      "Training loss: -0.0003830773893643315\n",
      "Training loss: -0.0003830497237167003\n",
      "Training loss: -0.00038302206087204103\n",
      "Training loss: -0.0003829944008299929\n",
      "Training loss: -0.00038296674359018985\n",
      "Training loss: -0.00038293908915226603\n",
      "Training loss: -0.0003829114375158591\n",
      "Training loss: -0.0003828837886806055\n",
      "Training loss: -0.0003828561426461408\n",
      "Training loss: -0.00038282849941210167\n",
      "Training loss: -0.0003828008589781224\n",
      "Training loss: -0.0003827732213438395\n",
      "Training loss: -0.0003827455865088903\n",
      "Training loss: -0.00038271795447291127\n",
      "Training loss: -0.000382690325235538\n",
      "Training loss: -0.00038266269879640657\n",
      "Training loss: -0.00038263507515515487\n",
      "Training loss: -0.0003826074543114178\n",
      "Training loss: -0.00038257983626483334\n",
      "Training loss: -0.0003825522210150365\n",
      "Training loss: -0.0003825246085616668\n",
      "Training loss: -0.00038249699890435785\n",
      "Training loss: -0.00038246939204274676\n"
     ]
    }
   ],
   "source": [
    "params = calculate_gradient()\n",
    "y_pred = params[0]*X +  params[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9c64978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final loss for this model: -0.00038246939204274676\n",
      "The final parameters are:\n",
      "weight:0.8821136404551693 , bias:0.002790306128780475\n"
     ]
    }
   ],
   "source": [
    "#printing the params and the losses for the regression model.\n",
    "print(\"The final loss for this model: {}\".format(losses[-1]))\n",
    "print(\"The final parameters are:\\nweight:{} , bias:{}\".format(params[0],params[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d092b986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(X,y)\n",
    "plt.scatter(X,y_pred);\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.grid()\n",
    "plt.legend(['Actual','Predicted']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac94796",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
